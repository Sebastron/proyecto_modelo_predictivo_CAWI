{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Redes_neuronales_principal.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ma037ufEzmze",
        "nPx4P5kUxncY",
        "ZRpaO0ObzipL",
        "eo6LCls93g7C",
        "WE2Iglwr5qvp",
        "jbaXujUm5kL5",
        "7fjQ33aLQOcr",
        "oa1MOnkYSksH",
        "FaVpYe4EDfkj"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ma037ufEzmze"
      },
      "source": [
        "# Instalación de dependencias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeftdK6GfSzU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "577b1de2-4aee-4a77-beef-4ffe9d92fca3"
      },
      "source": [
        "!pip install keras"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPx4P5kUxncY"
      },
      "source": [
        "# Librerias y/o dependencias a utilizar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4owP9IoaPEew"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from sklearn import preprocessing \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard,EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "import datetime\n",
        "from keras.utils import np_utils\n",
        "import seaborn as sns\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze -> requirimientos.txt"
      ],
      "metadata": {
        "id": "08wHsctNg5sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRpaO0ObzipL"
      },
      "source": [
        "# Lectura del dataset de prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8yjP5zUxs2q",
        "outputId": "965ee408-e473-486c-9331-009030c806f3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "path = '/content/drive/My Drive/Trabajo de título/TT2/Red neuronal/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "9U2J0rGgTVdQ",
        "outputId": "57ef9f92-7948-46cb-ca44-cf2615e070de"
      },
      "source": [
        "df = pd.read_csv(path + 'Dataset_de_prueba_oficial_1.csv', sep=';')\n",
        "df2 = pd.read_csv(path + 'Dataset_de_prueba_oficial_2.csv', sep=';')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-892f707e-a258-4963-a244-152d131a85d6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Segmento</th>\n",
              "      <th>SubSegmento</th>\n",
              "      <th>Segto_Agrup</th>\n",
              "      <th>Carterizado</th>\n",
              "      <th>Apertura</th>\n",
              "      <th>Hora_envio</th>\n",
              "      <th>Dia_semana</th>\n",
              "      <th>Mes_envio</th>\n",
              "      <th>RESPONDIDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991682</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991683</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991684</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991685</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991686</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3991687 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-892f707e-a258-4963-a244-152d131a85d6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-892f707e-a258-4963-a244-152d131a85d6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-892f707e-a258-4963-a244-152d131a85d6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Sexo      Edad  Segmento  ...  Dia_semana  Mes_envio  RESPONDIDA\n",
              "0         0.0  0.000000       0.0  ...    1.000000        0.0         0.0\n",
              "1         1.0  0.333333       0.0  ...    1.000000        0.0         0.0\n",
              "2         1.0  0.333333       0.0  ...    0.833333        0.0         0.0\n",
              "3         1.0  0.333333       0.0  ...    0.500000        0.0         0.0\n",
              "4         1.0  0.333333       0.5  ...    1.000000        0.0         0.0\n",
              "...       ...       ...       ...  ...         ...        ...         ...\n",
              "3991682   0.0  0.000000       0.0  ...    0.500000        1.0         0.0\n",
              "3991683   1.0  0.333333       0.5  ...    0.333333        1.0         0.0\n",
              "3991684   0.0  0.333333       1.0  ...    0.833333        1.0         0.0\n",
              "3991685   0.0  0.333333       1.0  ...    0.333333        1.0         0.0\n",
              "3991686   1.0  0.333333       1.0  ...    0.666667        1.0         0.0\n",
              "\n",
              "[3991687 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: total number of rows (3991687) exceeds max_rows (20000). Limiting to first (20000) rows.\n",
            "Warning: total number of rows (3991687) exceeds max_rows (20000). Limiting to first (20000) rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "aZe1lUSM0C3s",
        "outputId": "d2e8a552-8596-44e1-8e7e-15e4ffbd4095"
      },
      "source": [
        "df2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Segmento</th>\n",
              "      <th>SubSegmento</th>\n",
              "      <th>Segto_Agrup</th>\n",
              "      <th>Carterizado</th>\n",
              "      <th>Apertura</th>\n",
              "      <th>Hora_envio</th>\n",
              "      <th>Dia_semana</th>\n",
              "      <th>Mes_envio</th>\n",
              "      <th>RESPONDIDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499064</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499065</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.384615</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499066</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499067</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499068</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2499069 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sexo      Edad  Segmento  ...  Dia_semana  Mes_envio  RESPONDIDA\n",
              "0         0.0  0.000000       0.0  ...    1.000000        0.0         0.0\n",
              "1         1.0  0.333333       0.0  ...    1.000000        0.0         0.0\n",
              "2         1.0  0.333333       1.0  ...    1.000000        0.0         0.0\n",
              "3         0.0  0.666667       0.5  ...    1.000000        0.0         0.0\n",
              "4         1.0  0.666667       0.5  ...    0.333333        0.0         0.0\n",
              "...       ...       ...       ...  ...         ...        ...         ...\n",
              "2499064   0.0  1.000000       0.5  ...    0.166667        1.0         0.0\n",
              "2499065   0.0  0.666667       0.5  ...    0.333333        1.0         0.0\n",
              "2499066   1.0  0.333333       0.0  ...    0.333333        1.0         0.0\n",
              "2499067   1.0  0.333333       0.0  ...    0.000000        1.0         0.0\n",
              "2499068   1.0  0.666667       1.0  ...    0.000000        1.0         0.0\n",
              "\n",
              "[2499069 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N234RjvPC-vi",
        "outputId": "7e3f1610-cf2f-4562-dadb-9c07f718fc00"
      },
      "source": [
        "df['Mes_envio'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.09090909, 0.18181818, 0.27272727, 0.36363636,\n",
              "       0.45454545, 0.54545455, 0.63636364, 0.72727273, 0.81818182,\n",
              "       0.90909091, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOTKTdnIbfeb",
        "outputId": "1248eb9e-65ad-42f7-83e7-eda13b732246"
      },
      "source": [
        "df[(df['Mes_envio']<0.5)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2189349, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuqkb_oGEbrh",
        "outputId": "4816d45f-7ef0-4cb0-f929-8e9db358fb3c"
      },
      "source": [
        "df[(df['Mes_envio']<0.5)&(df['RESPONDIDA']==1)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56944, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zd9pOPPObvF5",
        "outputId": "75965e8f-6454-41c2-ea59-a2c1abcf76e5"
      },
      "source": [
        "df[(df['Mes_envio']>=0.5)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1802338, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rzlkYTLbkzn",
        "outputId": "453185a0-932b-43ff-ae2c-98bdf53f4da0"
      },
      "source": [
        "df[(df['Mes_envio']>=0.5)&(df['RESPONDIDA']==1)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50199, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR5Q9mfCep1A",
        "outputId": "187e703c-3ca2-4868-f5cd-08514ed3359e"
      },
      "source": [
        "df2[(df2['Mes_envio']<0.5)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1520840, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4P_XRQwerWf",
        "outputId": "346bc4f9-d689-47ce-84e2-c36624dc72c6"
      },
      "source": [
        "df2[(df2['Mes_envio']<0.5)&(df2['RESPONDIDA']==1)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(56944, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlzg4T2Ee0kk",
        "outputId": "b016dcb6-cdd9-4ff3-ee8f-e5ffc0a84bdb"
      },
      "source": [
        "df2[(df2['Mes_envio']>=0.5)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(978229, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iKDGWRcevSl",
        "outputId": "46ba03e6-22c8-45a4-b71e-0a697d944346"
      },
      "source": [
        "df2[(df2['Mes_envio']>=0.5)&(df2['RESPONDIDA']==1)].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50199, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUv8rQRVUWli"
      },
      "source": [
        "#Variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cLkzJ5qUgMY"
      },
      "source": [
        "###Independientes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q2bOpRFUl6n",
        "outputId": "75735ccf-2f87-4e57-e527-9b24332b587c"
      },
      "source": [
        "X1 = df.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "X2 = df2.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "X1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.07692308, 1.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.33333333, 0.        , ..., 0.46153846, 1.        ,\n",
              "        0.        ],\n",
              "       [1.        , 0.33333333, 0.        , ..., 0.        , 0.83333333,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.33333333, 1.        , ..., 0.61538462, 0.83333333,\n",
              "        1.        ],\n",
              "       [0.        , 0.33333333, 1.        , ..., 0.84615385, 0.33333333,\n",
              "        1.        ],\n",
              "       [1.        , 0.33333333, 1.        , ..., 0.69230769, 0.66666667,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2iNOXSTkJdZ",
        "outputId": "749c89ee-49fb-4cf1-848b-d0908014a13f"
      },
      "source": [
        "X1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3991687, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gq1QhgeWhN8",
        "outputId": "0da43550-d34b-4280-ab61-1381ac6531fa"
      },
      "source": [
        "X2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2499069, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWBPzsLAU_AG"
      },
      "source": [
        "###Objetivo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzhhZojJVDiw"
      },
      "source": [
        "Y1 = df[\"RESPONDIDA\"].to_numpy()\n",
        "Y2 = df2[\"RESPONDIDA\"].to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtzVgTUFXCWk",
        "outputId": "2de31e2b-ccbf-4fe8-df29-ca524a6e0258"
      },
      "source": [
        "Y1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3991687,)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psJVgt8DW3e3",
        "outputId": "cc365e41-dae6-44b4-9e57-5c99a476d0ee"
      },
      "source": [
        "Y2.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2499069,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i9pSy2i1vYr"
      },
      "source": [
        "# Red neuronal oficial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo6LCls93g7C"
      },
      "source": [
        "## Particion de datos de entrenamiento y prueba"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O8vUJCAbAKC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztFiWRZvcZXi",
        "outputId": "3556c2a6-c0db-45b7-d800-59c8053f4ff3"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1802338, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXejRFTOcdBi",
        "outputId": "51ff6e9c-f848-40f6-fe38-64a74a3f9e93"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1802338,)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6ie6DY-ch8u",
        "outputId": "bb54ca06-5511-4e4e-f5b3-68fd10df96c3"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2189349, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE23YVgScnbt",
        "outputId": "588aa5a0-890d-4443-c31d-671e3208dcff"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2189349, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00h38e-Alus_"
      },
      "source": [
        "# Split the data into a training set and a test set\n",
        "Train = df[(df['Mes_envio']<0.5)]\n",
        "X_train = Train.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "y_train = Train[\"RESPONDIDA\"].to_numpy()\n",
        "\n",
        "Test = df[(df['Mes_envio']>=0.5)]\n",
        "X_test = Test.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "y_test = Test[\"RESPONDIDA\"].to_numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BzpdWCd7ga"
      },
      "source": [
        "y_test = np_utils.to_categorical(y_test)\n",
        "y_train = np_utils.to_categorical(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "MNBiJrJlZKkc",
        "outputId": "cb4b8b0f-fcc9-4f83-b343-95c6fdcc93b1"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sexo</th>\n",
              "      <th>Edad</th>\n",
              "      <th>Segmento</th>\n",
              "      <th>SubSegmento</th>\n",
              "      <th>Segto_Agrup</th>\n",
              "      <th>Carterizado</th>\n",
              "      <th>Apertura</th>\n",
              "      <th>Hora_envio</th>\n",
              "      <th>Dia_semana</th>\n",
              "      <th>Mes_envio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076923</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991682</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991683</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.307692</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991684</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.615385</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991685</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3991686</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3991687 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Sexo      Edad  Segmento  ...  Hora_envio  Dia_semana  Mes_envio\n",
              "0         0.0  0.000000       0.0  ...    0.076923    1.000000        0.0\n",
              "1         1.0  0.333333       0.0  ...    0.461538    1.000000        0.0\n",
              "2         1.0  0.333333       0.0  ...    0.000000    0.833333        0.0\n",
              "3         1.0  0.333333       0.0  ...    0.769231    0.500000        0.0\n",
              "4         1.0  0.333333       0.5  ...    0.076923    1.000000        0.0\n",
              "...       ...       ...       ...  ...         ...         ...        ...\n",
              "3991682   0.0  0.000000       0.0  ...    0.615385    0.500000        1.0\n",
              "3991683   1.0  0.333333       0.5  ...    0.307692    0.333333        1.0\n",
              "3991684   0.0  0.333333       1.0  ...    0.615385    0.833333        1.0\n",
              "3991685   0.0  0.333333       1.0  ...    0.846154    0.333333        1.0\n",
              "3991686   1.0  0.333333       1.0  ...    0.692308    0.666667        1.0\n",
              "\n",
              "[3991687 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDhrLx4-ZHFC"
      },
      "source": [
        "Y = df['RESPONDIDA']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bw7N8-OHFQz-",
        "outputId": "afce8cf3-e563-4fd5-c750-6bde48d678cd"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2189349, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoSPo4tfMD7c",
        "outputId": "c0694792-b631-46c6-d719-c67264da2d94"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2189349,)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJTBKUE0k8p6"
      },
      "source": [
        "##Pruebas unitarias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        },
        "id": "QwQ4KAUUkf2U",
        "outputId": "213cb96f-26d6-428b-e50a-25cbfbb71f76"
      },
      "source": [
        "#activation= 'sigmoid', 'relu', 'softmax', 'tanh', 'elu'\n",
        "#loss='mean_squared_error', 'cross_entropy', 'categorical_crossentropy', 'binary_crossentropy' \n",
        "#Optimizador = 'adams', tf.train.GradientDescentOptimizer(learning_rate=0.1), tf.keras.optimizers.SGD(learning_rate=0.1)\n",
        "#Kernel_inicializacion = 'normal', 'uniform'\n",
        "#metrics = ['binary_accuracy'], ['accuracy']\n",
        "\n",
        "capas = [[25,'relu'],[40,'elu'],[100,'sigmoid'],[50,'sigmoid'],[25,'sigmoid'],[10,'elu']]\n",
        "f_perdida = 'mse'\n",
        "optimizador = 'Adamax'\n",
        "epocas = 1000\n",
        "tamano = 2200\n",
        "begin = datetime.datetime.now()\n",
        "\n",
        "#Arquitectura del modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim = 10, activation='relu'))\n",
        "for neuronas, funcion_activacion in capas:\n",
        "  model.add(Dense(neuronas, activation = funcion_activacion))\n",
        "model.add(Dense(2, activation = 'softmax', kernel_initializer='normal'))\n",
        "model.summary()\n",
        "\n",
        "# Compilar modelo\n",
        "model.compile(loss=f_perdida, optimizer=optimizador, metrics=['accuracy'])\n",
        "\n",
        "print(\"Entrando.....\")\n",
        "\n",
        "# Ajuste del modelo\n",
        "callEar = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1)\n",
        "model.fit(X_train, y_train, epochs = epocas, batch_size = tamano, callbacks=[callEar], verbose = 1)\n",
        "\n",
        "print(\"Saliendo.....\")\n",
        "\n",
        "tiempo = datetime.datetime.now()-begin\n",
        "print(\"Tiempo de ejecución: \", tiempo)\n",
        "\n",
        "scores = model.evaluate(X_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (\"Precisión\", scores[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                110       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 25)                275       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 40)                1040      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 100)               4100      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                5050      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 25)                1275      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                260       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 22        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,132\n",
            "Trainable params: 12,132\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Entrando.....\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 10s 9ms/step - loss: 0.0328 - accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "805/996 [=======================>......] - ETA: 1s - loss: 0.0194 - accuracy: 0.9744"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0876064c26a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Ajuste del modelo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcallEar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepocas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtamano\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallEar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saliendo.....\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5mDvvpsn0dm",
        "outputId": "daa88b12-ed86-489b-c461-b27b36e656e8"
      },
      "source": [
        "scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.039670877158641815, 0.9733973145484924]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFLCsmvUvwaa"
      },
      "source": [
        "new_predictions = model.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-RAhr4dyXfJ",
        "outputId": "a69e9290-344a-438c-a830-3c9502e10fb2"
      },
      "source": [
        "new_predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9999917e-01, 8.8650694e-07],\n",
              "       [9.9999905e-01, 9.5547591e-07],\n",
              "       [9.9999917e-01, 8.8967704e-07],\n",
              "       ...,\n",
              "       [9.9999881e-01, 1.1496123e-06],\n",
              "       [9.9999762e-01, 2.3554496e-06],\n",
              "       [9.9999893e-01, 1.1250881e-06]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6uVezgYP9KW"
      },
      "source": [
        "y_pred = np.round(new_predictions, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCNj7ZNjSD3C",
        "outputId": "68a76801-f5b3-40f4-81c5-dee9da19827e"
      },
      "source": [
        "y_pred[:,1]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "40f3SFRfTpZD",
        "outputId": "1014574f-5b24-4574-e51a-96b53754e501"
      },
      "source": [
        "respondida = pd.DataFrame(y_pred[:,1], columns = ['PRED_RESPONDIDA'])\n",
        "respondida"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRED_RESPONDIDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802333</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802334</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802335</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802336</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802337</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1802338 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         PRED_RESPONDIDA\n",
              "0                    0.0\n",
              "1                    0.0\n",
              "2                    0.0\n",
              "3                    0.0\n",
              "4                    0.0\n",
              "...                  ...\n",
              "1802333              0.0\n",
              "1802334              0.0\n",
              "1802335              0.0\n",
              "1802336              0.0\n",
              "1802337              0.0\n",
              "\n",
              "[1802338 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trXTPl1Klzod",
        "outputId": "c9735b3c-7e21-4957-ef68-a9a4760c1232"
      },
      "source": [
        "respondida['PRED_RESPONDIDA'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.  , 0.68, 0.63, 0.53, 0.51, 0.59, 0.52, 0.66, 0.56, 0.62, 0.5 ,\n",
              "       0.49, 0.55, 0.48, 0.65, 0.64, 0.54, 0.57, 0.69, 0.99, 0.61, 0.6 ,\n",
              "       0.47, 0.58, 0.67, 0.75, 0.96, 0.97, 0.98, 0.83, 0.7 , 0.39, 0.94,\n",
              "       0.95, 0.72, 0.89, 0.93, 0.82, 0.71, 0.8 , 0.78, 0.88, 0.87, 0.84,\n",
              "       0.81, 0.91, 0.85, 0.46, 0.01, 0.77, 0.73, 0.76, 0.9 , 0.79, 0.92,\n",
              "       0.09, 0.28, 0.03, 0.06, 0.08, 0.04, 0.37, 0.36, 0.02, 0.23, 0.19,\n",
              "       0.07, 0.21, 0.11, 0.16, 0.25, 0.14, 0.18, 0.13, 0.3 , 0.26, 0.29,\n",
              "       0.1 , 0.4 , 0.32, 0.45, 0.43, 0.38, 0.24, 0.05, 0.31, 0.42, 0.2 ,\n",
              "       0.12, 0.15, 0.22, 0.17, 0.35, 0.33, 0.27, 0.41, 0.34, 0.44, 0.74],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78KHR4Tgnl2N",
        "outputId": "903510d8-30a6-44f3-e2ab-40ba64df6d5e"
      },
      "source": [
        "respondida[respondida['PRED_RESPONDIDA']>=0.63].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42413, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvLHY0ROm5U4",
        "outputId": "a936a07f-94f4-4922-87ca-8bdf3254bcfc"
      },
      "source": [
        "freq = respondida[respondida['PRED_RESPONDIDA']>0.5].value_counts() \n",
        "\n",
        "print(freq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PRED_RESPONDIDA\n",
            "0.64               22476\n",
            "0.63               12724\n",
            "0.65               12532\n",
            "0.62                7583\n",
            "0.61                4806\n",
            "0.66                4266\n",
            "0.60                3712\n",
            "0.59                3291\n",
            "0.58                2969\n",
            "0.51                2166\n",
            "0.57                2115\n",
            "0.53                1919\n",
            "0.54                1906\n",
            "0.52                1888\n",
            "0.56                1885\n",
            "0.55                1776\n",
            "0.67                1471\n",
            "0.68                 966\n",
            "0.69                 371\n",
            "0.99                 149\n",
            "0.70                  34\n",
            "0.98                  18\n",
            "0.78                  11\n",
            "0.72                  11\n",
            "0.94                  10\n",
            "0.96                   9\n",
            "0.82                   8\n",
            "0.75                   7\n",
            "0.97                   6\n",
            "0.76                   6\n",
            "0.91                   6\n",
            "0.81                   6\n",
            "0.95                   6\n",
            "0.73                   5\n",
            "0.89                   5\n",
            "0.79                   4\n",
            "0.77                   4\n",
            "0.85                   4\n",
            "0.87                   4\n",
            "0.80                   4\n",
            "0.74                   3\n",
            "0.92                   2\n",
            "0.88                   2\n",
            "0.83                   2\n",
            "0.71                   2\n",
            "0.93                   1\n",
            "0.90                   1\n",
            "0.84                   1\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YeTTEBUT4gs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "dfn6qaCaXGUR",
        "outputId": "92e50d64-bba6-4a94-d197-cced8deb6070"
      },
      "source": [
        "respondida[respondida['PRED_RESPONDIDA']==1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRED_RESPONDIDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802262</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802265</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802273</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802280</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802328</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42413 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         PRED_RESPONDIDA\n",
              "10                   1.0\n",
              "99                   1.0\n",
              "127                  1.0\n",
              "186                  1.0\n",
              "196                  1.0\n",
              "...                  ...\n",
              "1802262              1.0\n",
              "1802265              1.0\n",
              "1802273              1.0\n",
              "1802280              1.0\n",
              "1802328              1.0\n",
              "\n",
              "[42413 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "FER-cn0UXWtC",
        "outputId": "376a200c-3836-4116-b24f-175ec6ff366b"
      },
      "source": [
        "respondida[respondida['PRED_RESPONDIDA']==0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PRED_RESPONDIDA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802333</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802334</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802335</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802336</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1802337</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1739618 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         PRED_RESPONDIDA\n",
              "0                    0.0\n",
              "1                    0.0\n",
              "2                    0.0\n",
              "3                    0.0\n",
              "4                    0.0\n",
              "...                  ...\n",
              "1802333              0.0\n",
              "1802334              0.0\n",
              "1802335              0.0\n",
              "1802336              0.0\n",
              "1802337              0.0\n",
              "\n",
              "[1739618 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzCTq1QLwOIi",
        "outputId": "f765b4cd-dc97-4b02-afe9-4bfaeb6091af"
      },
      "source": [
        "len(np.unique(new_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "137992"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4Hm8NQxz0Z2",
        "outputId": "86ea5601-9930-49ae-8149-9746510d6ed8"
      },
      "source": [
        "new_predictions.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1197507, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyYHl_0Jz8YK",
        "outputId": "4f17f32b-14d8-4508-ae60-6ad4620cfa6c"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1197507, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "HfEKR4P9yo1O",
        "outputId": "79d4a46d-3695-4fc8-b9e7-fe6f54ba9a22"
      },
      "source": [
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "confusion = confusion_matrix(y_test.argmax(axis=1), new_predictions.argmax(axis=1))\n",
        "#confusion = confusion_matrix(y_test, new_predictions)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                confusion.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     confusion.flatten()/np.sum(confusion)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[1707133   45006]\n",
            " [   2941   47258]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd6d877c790>"
            ]
          },
          "metadata": {},
          "execution_count": 259
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnnPn0II6uQo"
      },
      "source": [
        "# Guardar el Modelo\n",
        "model.save(path + 'Modelos/MejorModeloD1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icKEuvtRldiN"
      },
      "source": [
        "## Multi pruebas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huLIgHJrCp6M"
      },
      "source": [
        "def red_neuronal_dos_salidas(df, optimizador, f_perdida, capas, epocas, tamano):\n",
        "    #Particion de datos de entrenamiento y prueba\n",
        "    Train = df[(df['Mes_envio']<0.5)]\n",
        "    X_train = Train.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "    y_train = Train[\"RESPONDIDA\"].to_numpy()\n",
        "    Test = df[(df['Mes_envio']>=0.5)]\n",
        "    X_test = Test.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "    y_test = Test[\"RESPONDIDA\"].to_numpy()\n",
        "    y_test = np_utils.to_categorical(y_test)\n",
        "    y_train = np_utils.to_categorical(y_train)\n",
        "    #Arquitectura del modelo\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim = 10, activation='relu'))\n",
        "    for neuronas, funcion_activacion in capas:\n",
        "      model.add(Dense(neuronas, activation = funcion_activacion))\n",
        "    model.add(Dense(2, activation = 'softmax', kernel_initializer='normal'))\n",
        "    model.compile(loss=f_perdida, optimizer=optimizador, metrics=['binary_accuracy'])\n",
        "    # Ajuste del modelo\n",
        "    callEar = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1)\n",
        "    model.fit(X_train, y_train, epochs = epocas, batch_size = tamano, callbacks=[callEar], verbose = 1)\n",
        "    scores = model.evaluate(X_test, y_test)\n",
        "    precision = scores[1]\n",
        "    perdida = scores[0]\n",
        "    return precision, perdida, model\n",
        "\n",
        "def red_neuronal_una_salida(df, optimizador, f_perdida, capas, epocas, tamano):\n",
        "    #Particion de datos de entrenamiento y prueba\n",
        "    Train = df[(df['Mes_envio']<0.5)]\n",
        "    X_train = Train.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "    y_train = Train[\"RESPONDIDA\"].to_numpy()\n",
        "    Test = df[(df['Mes_envio']>=0.5)]\n",
        "    X_test = Test.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "    y_test = Test[\"RESPONDIDA\"].to_numpy()\n",
        "    #Arquitectura del modelo\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim = 10, activation='relu'))\n",
        "    for neuronas, funcion_activacion in capas:\n",
        "      model.add(Dense(neuronas, activation = funcion_activacion))\n",
        "    model.add(Dense(1, activation = 'relu', kernel_initializer='normal'))\n",
        "    model.compile(loss=f_perdida, optimizer=optimizador, metrics=['binary_accuracy'])\n",
        "    # Ajuste del modelo\n",
        "    callEar = EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1)\n",
        "    model.fit(X_train, y_train, epochs = epocas, batch_size = tamano, callbacks=[callEar], verbose = 1)\n",
        "    scores = model.evaluate(X_test, y_test)\n",
        "    precision = scores[1]\n",
        "    perdida = scores[0]\n",
        "    return precision, perdida, model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resultados redes neuronales por salida\n",
        "\n"
      ],
      "metadata": {
        "id": "e0XJKzUuP1Wo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Una salida"
      ],
      "metadata": {
        "id": "WE2Iglwr5qvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "df = pd.read_csv(path + 'Dataset_de_prueba_oficial_1.csv', sep=';')\n",
        "df2 = pd.read_csv(path + 'Dataset_de_prueba_oficial_2.csv', sep=';')\n",
        "\n",
        "# Definiciones Arquitecturas\n",
        "#activation= 'sigmoid', 'relu', 'softmax', 'tanh'\n",
        "#loss= 'categorical_crossentropy', \n",
        "#Optimizador = 'adams', 'sgd'\n",
        "\n",
        "#Modificar arreglo\n",
        "ejecuciones = [\n",
        "               ['Red9','sgd','categorical_crossentropy',[[30,'relu'],[65,'tanh'],[100, 'sigmoid'], [65,'relu'], [30,'tanh'], [10, 'sigmoid']]],\n",
        "               ['Red10','adam','categorical_crossentropy',[[25,'relu'],[60,'tanh'],[90, 'sigmoid'], [60,'relu'], [30,'tanh'], [15, 'sigmoid']]],\n",
        "               ['Red11','Adagrad','categorical_crossentropy',[[30,'sigmoid'],[55,'relu'],[90, 'tanh'], [65,'relu'], [35,'relu'], [10, 'sigmoid']]],\n",
        "               ['Red12','sgd','categorical_crossentropy',[[25,'sigmoid'],[50,'relu'],[90, 'tanh'], [120,'relu'], [80,'relu'], [50, 'sigmoid'], [20, 'sigmoid']]],\n",
        "               #['Red13','Adamax','categorical_crossentropy',[[20,'relu'],[50, 'sigmoid'],[25,'relu']]],\n",
        "               ['Red14','Adamax','categorical_crossentropy',[[25,'elu'],[40, 'sigmoid'],[60,'tanh'], [35,'sigmoid'], [15,'relu']]],\n",
        "               ['Red15','Adagrad','categorical_crossentropy',[[25,'sigmoid'],[50, 'elu'],[70,'relu'],[100,'tanh'], [65,'relu'], [25, 'sigmoid'], [10, 'elu']]],\n",
        "               #['Red16','adam','categorical_crossentropy',[[30,'sigmoid'],[55, 'elu'],[75,'relu'],[100,'tanh'], [70,'relu'], [35, 'sigmoid'], [15, 'elu']]],\n",
        "               #['Red17','sgd','categorical_crossentropy',[[25,'sigmoid'],[50, 'relu'],[75,'elu'],[100,'sigmoid'], [70,'tanh'], [35, 'relu'], [15, 'elu']]],\n",
        "               #['Red18','adam','categorical_crossentropy',[[20,'elu'],[50, 'relu'],[25,'elu'],[10,'sigmoid']]],\n",
        "               ['Red19','adam','categorical_crossentropy',[[25,'relu'],[45, 'softmax'],[20,'sigmoid'],[5,'sigmoid']]]\n",
        "               #['Red20','sgd','categorical_crossentropy',[[20,'softmax'],[50, 'sigmoid'],[25,'tanh'],[10,'relu']]]\n",
        "               ]\n",
        "arr = []\n",
        "for nombre, optimizador, f_perdida, arquitectura in ejecuciones:\n",
        "    for dataset in range (0, 2):\n",
        "      for i in range (1, 6):\n",
        "        # Entrenar la red\n",
        "        if(dataset == 0):\n",
        "          precision, perdida, Modelo =  red_neuronal_una_salida(df, optimizador, f_perdida, arquitectura, 1000, 2200) # Modificar funcion\n",
        "          arr.append([nombre, \"Dataset1\", i, optimizador, f_perdida, precision, perdida])\n",
        "        else:\n",
        "          precision, perdida, Modelo = red_neuronal_una_salida(df2, optimizador, f_perdida, arquitectura, 1000, 1550) # Modificar funcion\n",
        "          arr.append([nombre, \"Dataset2\", i, optimizador, f_perdida, precision, perdida])\n",
        "      if(dataset == 0):\n",
        "        # Guardar el Modelo\n",
        "        Modelo.save(path + 'Modelos/'+ nombre + '_D1S1.h5')\n",
        "      else:\n",
        "        # Guardar el Modelo\n",
        "        Modelo.save(path + 'Modelos/'+ nombre + '_D2S1.h5')\n",
        "# Documentar red)\n",
        "df_glob = pd.read_excel(path + 'Datos_Red_1_salidas.xlsx')\n",
        "df_salida = pd.DataFrame(arr,columns = ['Red', 'Dataset', 'Iteracion', 'Optimizador', 'F_Perdida', 'Precision', 'Perdida (loss)'])\n",
        "df_glob = pd.concat([df_glob, df_salida])\n",
        "df_glob.to_excel(path + 'Datos_Red_1_salidas.xlsx', index = False)\n",
        "df_glob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MjaXL0pJ5qD0",
        "outputId": "ccba66c8-c97b-4469-cb7d-9baf5034146e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 81s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 13s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 81s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 80s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 81s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 79s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 42s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 44s 1ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 43s 1ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 81s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 82s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 81s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 11s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 82s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 11s 11ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 80s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 44s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 44s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 43s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 13s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 83s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 84s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 13s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 86s 2ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 13s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 85s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 84s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 46s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 46s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 9s 10ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 10s 10ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 85s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 85s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 88s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 19s 18ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 86s 2ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 19s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 87s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 47s 2ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 47s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 49s 2ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 15s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 48s 2ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 13s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 14s 14ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 47s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 8s 9ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 82s 1ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 84s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 10s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 84s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 8s 8ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 83s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 10s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 9s 9ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 84s 1ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 46s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 46s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 44s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 8s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 44s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 45s 1ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 87s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 16s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 91s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 90s 2ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 89s 2ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 16s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 89s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 49s 2ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 12s 12ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 49s 2ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 49s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 50s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 12s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 13s 13ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 50s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 8s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 86s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 8s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 86s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 8s 7ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: 3.1006e-09 - binary_accuracy: 0.9740\n",
            "Epoch 00006: early stopping\n",
            "56324/56324 [==============================] - 86s 2ms/step - loss: 3.3202e-09 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 8s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 85s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 8s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 7s 7ms/step - loss: nan - binary_accuracy: 0.9740\n",
            "Epoch 00005: early stopping\n",
            "56324/56324 [==============================] - 85s 2ms/step - loss: nan - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 6s 5ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: nan - binary_accuracy: 0.9626\n",
            "Epoch 00005: early stopping\n",
            "30570/30570 [==============================] - 47s 2ms/step - loss: nan - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 6s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 47s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 6s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 6s 6ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 48s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 6s 6ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 6s 6ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 47s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n",
            "Epoch 1/1000\n",
            "982/982 [==============================] - 6s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 2/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 3/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 4/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 5/1000\n",
            "982/982 [==============================] - 5s 6ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 6/1000\n",
            "982/982 [==============================] - 5s 5ms/step - loss: 4.4635e-09 - binary_accuracy: 0.9626\n",
            "Epoch 00006: early stopping\n",
            "30570/30570 [==============================] - 48s 2ms/step - loss: 6.1174e-09 - binary_accuracy: 0.9487\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Red</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Iteracion</th>\n",
              "      <th>Optimizador</th>\n",
              "      <th>F_Perdida</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Perdida (loss)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Red13</td>\n",
              "      <td>Dataset1</td>\n",
              "      <td>1</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.972148</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Red13</td>\n",
              "      <td>Dataset1</td>\n",
              "      <td>2</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.972148</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Red13</td>\n",
              "      <td>Dataset1</td>\n",
              "      <td>3</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.972148</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Red13</td>\n",
              "      <td>Dataset1</td>\n",
              "      <td>4</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.972148</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Red13</td>\n",
              "      <td>Dataset1</td>\n",
              "      <td>5</td>\n",
              "      <td>Adamax</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.972148</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Red19</td>\n",
              "      <td>Dataset2</td>\n",
              "      <td>1</td>\n",
              "      <td>adam</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Red19</td>\n",
              "      <td>Dataset2</td>\n",
              "      <td>2</td>\n",
              "      <td>adam</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>6.117369e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>Red19</td>\n",
              "      <td>Dataset2</td>\n",
              "      <td>3</td>\n",
              "      <td>adam</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>6.117369e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>Red19</td>\n",
              "      <td>Dataset2</td>\n",
              "      <td>4</td>\n",
              "      <td>adam</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>6.117369e-09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>Red19</td>\n",
              "      <td>Dataset2</td>\n",
              "      <td>5</td>\n",
              "      <td>adam</td>\n",
              "      <td>categorical_crossentropy</td>\n",
              "      <td>0.948684</td>\n",
              "      <td>6.117369e-09</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>180 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Red   Dataset  ...  Precision Perdida (loss)\n",
              "0   Red13  Dataset1  ...   0.972148   0.000000e+00\n",
              "1   Red13  Dataset1  ...   0.972148   0.000000e+00\n",
              "2   Red13  Dataset1  ...   0.972148   0.000000e+00\n",
              "3   Red13  Dataset1  ...   0.972148   0.000000e+00\n",
              "4   Red13  Dataset1  ...   0.972148   0.000000e+00\n",
              "..    ...       ...  ...        ...            ...\n",
              "65  Red19  Dataset2  ...   0.948684            NaN\n",
              "66  Red19  Dataset2  ...   0.948684   6.117369e-09\n",
              "67  Red19  Dataset2  ...   0.948684   6.117369e-09\n",
              "68  Red19  Dataset2  ...   0.948684   6.117369e-09\n",
              "69  Red19  Dataset2  ...   0.948684   6.117369e-09\n",
              "\n",
              "[180 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dos salidas"
      ],
      "metadata": {
        "id": "jbaXujUm5kL5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJePswoxt3sZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cfbffb-e534-455e-f2f5-019f5dbc0bf3"
      },
      "source": [
        "# Datasets\n",
        "df = pd.read_csv(path + 'Dataset_de_prueba_oficial_1.csv', sep=';')\n",
        "df2 = pd.read_csv(path + 'Dataset_de_prueba_oficial_2.csv', sep=';')\n",
        "\n",
        "# Definiciones Arquitecturas\n",
        "#activation= 'sigmoid', 'relu', 'softmax', 'tanh'\n",
        "#loss= 'categorical_crossentropy', \n",
        "#Optimizador = 'adams', 'sgd'\n",
        "\n",
        "#Modificar arreglo\n",
        "ejecuciones = [\n",
        "               #['Red9','sgd','categorical_crossentropy',[[30,'relu'],[65,'tanh'],[100, 'sigmoid'], [65,'relu'], [30,'tanh'], [10, 'sigmoid']]]\n",
        "               #['Red10','adam','categorical_crossentropy',[[25,'relu'],[60,'tanh'],[90, 'sigmoid'], [60,'relu'], [30,'tanh'], [15, 'sigmoid']]],\n",
        "               ['Red11','Adagrad','categorical_crossentropy',[[30,'sigmoid'],[55,'relu'],[90, 'tanh'], [65,'relu'], [35,'relu'], [10, 'sigmoid']]],\n",
        "               #['Red12','sgd','categorical_crossentropy',[[25,'sigmoid'],[50,'relu'],[90, 'tanh'], [120,'relu'], [80,'relu'], [50, 'sigmoid'], [20, 'sigmoid']]],\n",
        "               #['Red13','Adamax','categorical_crossentropy',[[20,'relu'],[50, 'sigmoid'],[25,'relu']]],\n",
        "               #['Red14','Adamax','categorical_crossentropy',[[25,'elu'],[40, 'sigmoid'],[60,'tanh'], [35,'sigmoid'], [15,'relu']]],\n",
        "               #['Red15','Adagrad','categorical_crossentropy',[[25,'sigmoid'],[50, 'elu'],[70,'relu'],[100,'tanh'], [65,'relu'], [25, 'sigmoid'], [10, 'elu']]]\n",
        "               #['Red16','adam','categorical_crossentropy',[[30,'sigmoid'],[55, 'elu'],[75,'relu'],[100,'tanh'], [70,'relu'], [35, 'sigmoid'], [15, 'elu']]],\n",
        "               #['Red17','sgd','categorical_crossentropy',[[25,'sigmoid'],[50, 'relu'],[75,'elu'],[100,'sigmoid'], [70,'tanh'], [35, 'relu'], [15, 'elu']]],\n",
        "               #['Red18','adam','categorical_crossentropy',[[20,'elu'],[50, 'relu'],[25,'elu'],[10,'sigmoid']]],\n",
        "               #['Red19','adam','categorical_crossentropy',[[25,'relu'],[45, 'softmax'],[20,'sigmoid'],[5,'sigmoid']]],\n",
        "               #['Red20','sgd','categorical_crossentropy',[[20,'softmax'],[50, 'sigmoid'],[25,'tanh'],[10,'relu']]]\n",
        "               ]\n",
        "arr = []\n",
        "for nombre, optimizador, f_perdida, arquitectura in ejecuciones:\n",
        "  \n",
        "    for dataset in range (0, 2):\n",
        "      for i in range (1, 6):\n",
        "        # Entrenar la red\n",
        "        if(dataset == 0):\n",
        "          precision, perdida, Modelo =  red_neuronal_dos_salidas(df, optimizador, f_perdida, arquitectura, 1000, 2200) # Modificar funcion\n",
        "          arr.append([nombre, \"Dataset1\", i, optimizador, f_perdida, precision, perdida])\n",
        "        else:\n",
        "          precision, perdida, Modelo = red_neuronal_dos_salidas(df2, optimizador, f_perdida, arquitectura, 1000, 1550) # Modificar funcion\n",
        "          arr.append([nombre, \"Dataset2\", i, optimizador, f_perdida, precision, perdida])\n",
        "      if(dataset == 0):\n",
        "        # Guardar el Modelo\n",
        "        Modelo.save(path + 'Modelos/'+ nombre + '_D1S2.h5')\n",
        "      else:\n",
        "        # Guardar el Modelo\n",
        "        Modelo.save(path + 'Modelos/'+ nombre + '_D2S2.h5')\n",
        "# Documentar red)\n",
        "df_glob = pd.read_excel(path + 'Datos_Red_2_salidas.xlsx')\n",
        "df_salida = pd.DataFrame(arr,columns = ['Red', 'Dataset', 'Iteracion', 'Optimizador', 'F_Perdida', 'Precision', 'Perdida (loss)'])\n",
        "df_glob = pd.concat([df_glob, df_salida])\n",
        "df_glob.to_excel(path + 'Datos_Red_2_salidas.xlsx', index = False)\n",
        "df_glob"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.5189 - binary_accuracy: 0.9587\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.3499 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.2484 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1979 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1740 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1604 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1516 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1455 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1410 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1375 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1348 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1326 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1309 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1295 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1283 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1272 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1264 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1257 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1251 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1245 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1241 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1237 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1233 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1230 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1228 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1225 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1223 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 11s 12ms/step - loss: 0.1221 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1220 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1218 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1217 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1216 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1215 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1214 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1213 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1212 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1212 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1211 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1211 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1210 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1210 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 11s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 11s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 00138: early stopping\n",
            "56324/56324 [==============================] - 77s 1ms/step - loss: 0.1272 - binary_accuracy: 0.9721\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 13s 12ms/step - loss: 0.5398 - binary_accuracy: 0.9240\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.3575 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.2679 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.2205 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1925 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1739 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1612 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1522 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1458 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1411 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1376 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1348 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1326 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1308 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1294 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1282 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1272 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1263 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1256 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1250 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1245 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1240 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1236 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1233 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1230 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1227 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1225 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1223 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1221 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1220 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1218 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1217 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1216 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1215 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1214 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1213 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1213 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1212 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1211 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1211 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1210 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1210 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 12s 13ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 12s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 12s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 12s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 12s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 198/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 199/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 200/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 201/1000\n",
            "996/996 [==============================] - 12s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 202/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 203/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 204/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 205/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 206/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 207/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 208/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 209/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 210/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 211/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 212/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 213/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 214/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 215/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 216/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 217/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 218/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 219/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 220/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 221/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 222/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 223/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 224/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 225/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 226/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 227/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 228/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 229/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 230/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 231/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 232/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 233/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 234/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 235/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 236/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 237/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 238/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 239/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 240/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 241/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 242/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 243/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 244/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 245/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 246/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 247/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 248/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 249/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 250/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 251/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 252/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 253/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 254/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 255/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 256/1000\n",
            "996/996 [==============================] - 12s 12ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 257/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 258/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 259/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 260/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 261/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 262/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 263/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 264/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 265/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 266/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 267/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 268/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 269/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 270/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 271/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 272/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 273/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 274/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 275/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 276/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 277/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 278/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 279/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 280/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 281/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 282/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 283/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 284/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 285/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 286/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 287/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 288/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 289/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 290/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 291/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 292/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 293/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 294/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 295/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 296/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 297/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 298/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 299/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 300/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 301/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 302/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 303/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 304/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 305/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 306/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 307/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 308/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 309/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 310/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 311/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 312/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 313/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 314/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 315/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 316/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 317/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 318/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 319/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 320/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 321/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 322/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 323/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 324/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 325/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 326/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 327/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 328/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 329/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 330/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 331/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 332/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 333/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 334/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 335/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 336/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 337/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 338/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 339/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 340/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 341/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 342/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 343/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 344/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 345/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 346/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 347/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 348/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 349/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 350/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 351/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 352/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 353/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 354/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 355/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 356/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 357/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 358/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 359/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 360/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 361/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 362/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 363/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 364/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 365/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 366/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 367/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 368/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 369/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 370/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 371/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 372/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 373/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 374/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 375/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 376/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 377/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 378/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 379/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 380/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 381/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 382/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 383/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 384/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 385/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 386/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 387/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 388/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 389/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 390/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 391/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 392/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 393/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 394/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 395/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 396/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 397/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 398/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 399/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 400/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 401/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 402/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 403/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 404/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 405/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 406/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 407/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 408/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 409/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 410/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 411/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 412/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 413/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 414/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 415/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 416/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 417/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 418/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 419/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 420/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 421/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 422/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 423/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 424/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 425/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 426/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 427/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 428/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 429/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 430/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 431/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 432/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 433/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 434/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 435/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 436/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 437/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 438/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 439/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 440/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 441/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 442/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 443/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 444/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 445/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 446/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 447/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 448/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 449/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 450/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 451/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 452/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 453/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 454/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 455/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 456/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 457/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 458/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 459/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 460/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 461/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 462/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 463/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 464/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 465/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 466/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 467/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 468/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 469/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 470/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 471/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 472/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 473/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 474/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 475/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 476/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 477/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 478/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 479/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 480/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 481/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 482/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 483/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 484/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 485/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 486/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 487/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 488/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 489/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 490/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 491/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 492/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 493/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 494/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 495/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 496/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 497/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 498/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 499/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 500/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 501/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 502/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 503/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 504/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 505/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 506/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 507/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 508/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 509/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 510/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 511/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 512/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 513/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 514/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 515/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 516/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 517/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 518/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 519/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 520/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 521/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 522/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 523/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 524/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 525/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 526/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 527/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 528/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 529/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 530/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 531/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 532/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 533/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 534/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 535/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 536/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 537/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 538/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 539/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 540/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 541/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 542/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 543/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 544/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 545/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 546/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 547/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 548/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 549/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 550/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 551/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 552/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 553/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 554/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 555/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 556/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 557/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 558/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 559/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 560/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 561/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 562/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 563/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 564/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 565/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 566/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 567/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 568/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 569/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 570/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 571/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 572/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 573/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 574/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 575/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 576/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 577/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 578/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 579/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 580/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 581/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1195 - binary_accuracy: 0.9740\n",
            "Epoch 582/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1195 - binary_accuracy: 0.9740\n",
            "Epoch 583/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1195 - binary_accuracy: 0.9740\n",
            "Epoch 584/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 585/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 586/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1193 - binary_accuracy: 0.9740\n",
            "Epoch 587/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1193 - binary_accuracy: 0.9740\n",
            "Epoch 588/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1193 - binary_accuracy: 0.9740\n",
            "Epoch 589/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 590/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 591/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1191 - binary_accuracy: 0.9740\n",
            "Epoch 592/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1190 - binary_accuracy: 0.9740\n",
            "Epoch 593/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1190 - binary_accuracy: 0.9740\n",
            "Epoch 594/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1189 - binary_accuracy: 0.9740\n",
            "Epoch 595/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1188 - binary_accuracy: 0.9740\n",
            "Epoch 596/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1188 - binary_accuracy: 0.9740\n",
            "Epoch 597/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1187 - binary_accuracy: 0.9740\n",
            "Epoch 598/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1186 - binary_accuracy: 0.9740\n",
            "Epoch 599/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1185 - binary_accuracy: 0.9740\n",
            "Epoch 600/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1184 - binary_accuracy: 0.9740\n",
            "Epoch 601/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1183 - binary_accuracy: 0.9740\n",
            "Epoch 602/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1182 - binary_accuracy: 0.9740\n",
            "Epoch 603/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1180 - binary_accuracy: 0.9740\n",
            "Epoch 604/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1179 - binary_accuracy: 0.9740\n",
            "Epoch 605/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1178 - binary_accuracy: 0.9740\n",
            "Epoch 606/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1176 - binary_accuracy: 0.9740\n",
            "Epoch 607/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1174 - binary_accuracy: 0.9740\n",
            "Epoch 608/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1172 - binary_accuracy: 0.9740\n",
            "Epoch 609/1000\n",
            "996/996 [==============================] - 13s 14ms/step - loss: 0.1170 - binary_accuracy: 0.9740\n",
            "Epoch 610/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1168 - binary_accuracy: 0.9740\n",
            "Epoch 611/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1165 - binary_accuracy: 0.9740\n",
            "Epoch 612/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1162 - binary_accuracy: 0.9740\n",
            "Epoch 613/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1159 - binary_accuracy: 0.9740\n",
            "Epoch 614/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1156 - binary_accuracy: 0.9740\n",
            "Epoch 615/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1152 - binary_accuracy: 0.9740\n",
            "Epoch 616/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1148 - binary_accuracy: 0.9740\n",
            "Epoch 617/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1143 - binary_accuracy: 0.9740\n",
            "Epoch 618/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1138 - binary_accuracy: 0.9740\n",
            "Epoch 619/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1133 - binary_accuracy: 0.9740\n",
            "Epoch 620/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1126 - binary_accuracy: 0.9740\n",
            "Epoch 621/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1119 - binary_accuracy: 0.9740\n",
            "Epoch 622/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1111 - binary_accuracy: 0.9740\n",
            "Epoch 623/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1102 - binary_accuracy: 0.9740\n",
            "Epoch 624/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1091 - binary_accuracy: 0.9740\n",
            "Epoch 625/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1080 - binary_accuracy: 0.9740\n",
            "Epoch 626/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1068 - binary_accuracy: 0.9740\n",
            "Epoch 627/1000\n",
            "996/996 [==============================] - 13s 13ms/step - loss: 0.1055 - binary_accuracy: 0.9740\n",
            "Epoch 628/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1041 - binary_accuracy: 0.9740\n",
            "Epoch 629/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1026 - binary_accuracy: 0.9740\n",
            "Epoch 630/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1010 - binary_accuracy: 0.9740\n",
            "Epoch 631/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0993 - binary_accuracy: 0.9740\n",
            "Epoch 632/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0975 - binary_accuracy: 0.9740\n",
            "Epoch 633/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0955 - binary_accuracy: 0.9740\n",
            "Epoch 634/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0935 - binary_accuracy: 0.9740\n",
            "Epoch 635/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0914 - binary_accuracy: 0.9740\n",
            "Epoch 636/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0891 - binary_accuracy: 0.9740\n",
            "Epoch 637/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0869 - binary_accuracy: 0.9740\n",
            "Epoch 638/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0846 - binary_accuracy: 0.9740\n",
            "Epoch 639/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0823 - binary_accuracy: 0.9740\n",
            "Epoch 640/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0800 - binary_accuracy: 0.9740\n",
            "Epoch 641/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0777 - binary_accuracy: 0.9740\n",
            "Epoch 642/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0755 - binary_accuracy: 0.9740\n",
            "Epoch 643/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0733 - binary_accuracy: 0.9740\n",
            "Epoch 644/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0712 - binary_accuracy: 0.9740\n",
            "Epoch 645/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0692 - binary_accuracy: 0.9740\n",
            "Epoch 646/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0674 - binary_accuracy: 0.9740\n",
            "Epoch 647/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0656 - binary_accuracy: 0.9740\n",
            "Epoch 648/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0640 - binary_accuracy: 0.9740\n",
            "Epoch 649/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0625 - binary_accuracy: 0.9740\n",
            "Epoch 650/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0612 - binary_accuracy: 0.9740\n",
            "Epoch 651/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0599 - binary_accuracy: 0.9740\n",
            "Epoch 652/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0587 - binary_accuracy: 0.9740\n",
            "Epoch 653/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0577 - binary_accuracy: 0.9740\n",
            "Epoch 654/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0567 - binary_accuracy: 0.9740\n",
            "Epoch 655/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0558 - binary_accuracy: 0.9740\n",
            "Epoch 656/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0550 - binary_accuracy: 0.9740\n",
            "Epoch 657/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0542 - binary_accuracy: 0.9740\n",
            "Epoch 658/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0535 - binary_accuracy: 0.9740\n",
            "Epoch 659/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0529 - binary_accuracy: 0.9740\n",
            "Epoch 660/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0523 - binary_accuracy: 0.9740\n",
            "Epoch 661/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0517 - binary_accuracy: 0.9740\n",
            "Epoch 662/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0512 - binary_accuracy: 0.9740\n",
            "Epoch 663/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0507 - binary_accuracy: 0.9740\n",
            "Epoch 664/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0503 - binary_accuracy: 0.9740\n",
            "Epoch 665/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0499 - binary_accuracy: 0.9740\n",
            "Epoch 666/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0495 - binary_accuracy: 0.9740\n",
            "Epoch 667/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0491 - binary_accuracy: 0.9740\n",
            "Epoch 668/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0488 - binary_accuracy: 0.9740\n",
            "Epoch 669/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0484 - binary_accuracy: 0.9740\n",
            "Epoch 670/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0481 - binary_accuracy: 0.9740\n",
            "Epoch 671/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0478 - binary_accuracy: 0.9740\n",
            "Epoch 672/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0476 - binary_accuracy: 0.9740\n",
            "Epoch 673/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0473 - binary_accuracy: 0.9740\n",
            "Epoch 674/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0471 - binary_accuracy: 0.9740\n",
            "Epoch 675/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0468 - binary_accuracy: 0.9740\n",
            "Epoch 676/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0466 - binary_accuracy: 0.9740\n",
            "Epoch 677/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0464 - binary_accuracy: 0.9740\n",
            "Epoch 678/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0462 - binary_accuracy: 0.9740\n",
            "Epoch 679/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0460 - binary_accuracy: 0.9740\n",
            "Epoch 680/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0458 - binary_accuracy: 0.9740\n",
            "Epoch 681/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0457 - binary_accuracy: 0.9740\n",
            "Epoch 682/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0455 - binary_accuracy: 0.9740\n",
            "Epoch 683/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0454 - binary_accuracy: 0.9740\n",
            "Epoch 684/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0452 - binary_accuracy: 0.9740\n",
            "Epoch 685/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0451 - binary_accuracy: 0.9740\n",
            "Epoch 686/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0449 - binary_accuracy: 0.9740\n",
            "Epoch 687/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0448 - binary_accuracy: 0.9740\n",
            "Epoch 688/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0447 - binary_accuracy: 0.9740\n",
            "Epoch 689/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0445 - binary_accuracy: 0.9740\n",
            "Epoch 690/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0444 - binary_accuracy: 0.9740\n",
            "Epoch 691/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0443 - binary_accuracy: 0.9740\n",
            "Epoch 692/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0442 - binary_accuracy: 0.9740\n",
            "Epoch 693/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0441 - binary_accuracy: 0.9740\n",
            "Epoch 694/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0440 - binary_accuracy: 0.9740\n",
            "Epoch 695/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0439 - binary_accuracy: 0.9740\n",
            "Epoch 696/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0438 - binary_accuracy: 0.9740\n",
            "Epoch 697/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0437 - binary_accuracy: 0.9740\n",
            "Epoch 698/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0436 - binary_accuracy: 0.9740\n",
            "Epoch 699/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0435 - binary_accuracy: 0.9740\n",
            "Epoch 700/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0434 - binary_accuracy: 0.9740\n",
            "Epoch 701/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0433 - binary_accuracy: 0.9740\n",
            "Epoch 702/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0432 - binary_accuracy: 0.9740\n",
            "Epoch 703/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0432 - binary_accuracy: 0.9740\n",
            "Epoch 704/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0431 - binary_accuracy: 0.9740\n",
            "Epoch 705/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0430 - binary_accuracy: 0.9740\n",
            "Epoch 706/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0429 - binary_accuracy: 0.9740\n",
            "Epoch 707/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0429 - binary_accuracy: 0.9740\n",
            "Epoch 708/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0428 - binary_accuracy: 0.9740\n",
            "Epoch 709/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0427 - binary_accuracy: 0.9740\n",
            "Epoch 710/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0426 - binary_accuracy: 0.9740\n",
            "Epoch 711/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0426 - binary_accuracy: 0.9740\n",
            "Epoch 712/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0425 - binary_accuracy: 0.9740\n",
            "Epoch 713/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0425 - binary_accuracy: 0.9740\n",
            "Epoch 714/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0424 - binary_accuracy: 0.9740\n",
            "Epoch 715/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0423 - binary_accuracy: 0.9740\n",
            "Epoch 716/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0423 - binary_accuracy: 0.9740\n",
            "Epoch 717/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0422 - binary_accuracy: 0.9740\n",
            "Epoch 718/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0422 - binary_accuracy: 0.9740\n",
            "Epoch 719/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0421 - binary_accuracy: 0.9740\n",
            "Epoch 720/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0420 - binary_accuracy: 0.9740\n",
            "Epoch 721/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0420 - binary_accuracy: 0.9740\n",
            "Epoch 722/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0419 - binary_accuracy: 0.9740\n",
            "Epoch 723/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0419 - binary_accuracy: 0.9740\n",
            "Epoch 724/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0418 - binary_accuracy: 0.9740\n",
            "Epoch 725/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0418 - binary_accuracy: 0.9740\n",
            "Epoch 726/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0417 - binary_accuracy: 0.9740\n",
            "Epoch 727/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0417 - binary_accuracy: 0.9740\n",
            "Epoch 728/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0416 - binary_accuracy: 0.9740\n",
            "Epoch 729/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0416 - binary_accuracy: 0.9740\n",
            "Epoch 730/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0415 - binary_accuracy: 0.9740\n",
            "Epoch 731/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0415 - binary_accuracy: 0.9740\n",
            "Epoch 732/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0414 - binary_accuracy: 0.9740\n",
            "Epoch 733/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0414 - binary_accuracy: 0.9740\n",
            "Epoch 734/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0413 - binary_accuracy: 0.9740\n",
            "Epoch 735/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0413 - binary_accuracy: 0.9740\n",
            "Epoch 736/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0413 - binary_accuracy: 0.9740\n",
            "Epoch 737/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0412 - binary_accuracy: 0.9740\n",
            "Epoch 738/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0412 - binary_accuracy: 0.9740\n",
            "Epoch 739/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0411 - binary_accuracy: 0.9740\n",
            "Epoch 740/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0411 - binary_accuracy: 0.9740\n",
            "Epoch 741/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0410 - binary_accuracy: 0.9740\n",
            "Epoch 742/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0410 - binary_accuracy: 0.9740\n",
            "Epoch 743/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0410 - binary_accuracy: 0.9740\n",
            "Epoch 744/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0409 - binary_accuracy: 0.9740\n",
            "Epoch 745/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0409 - binary_accuracy: 0.9740\n",
            "Epoch 746/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0408 - binary_accuracy: 0.9740\n",
            "Epoch 747/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0408 - binary_accuracy: 0.9740\n",
            "Epoch 748/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0408 - binary_accuracy: 0.9740\n",
            "Epoch 749/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0407 - binary_accuracy: 0.9740\n",
            "Epoch 750/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0407 - binary_accuracy: 0.9740\n",
            "Epoch 751/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0407 - binary_accuracy: 0.9740\n",
            "Epoch 752/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0406 - binary_accuracy: 0.9740\n",
            "Epoch 753/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0406 - binary_accuracy: 0.9740\n",
            "Epoch 754/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0405 - binary_accuracy: 0.9740\n",
            "Epoch 755/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0405 - binary_accuracy: 0.9740\n",
            "Epoch 756/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0405 - binary_accuracy: 0.9740\n",
            "Epoch 757/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0404 - binary_accuracy: 0.9740\n",
            "Epoch 758/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0404 - binary_accuracy: 0.9740\n",
            "Epoch 759/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0404 - binary_accuracy: 0.9740\n",
            "Epoch 760/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0403 - binary_accuracy: 0.9740\n",
            "Epoch 761/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0403 - binary_accuracy: 0.9740\n",
            "Epoch 762/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0403 - binary_accuracy: 0.9740\n",
            "Epoch 763/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0402 - binary_accuracy: 0.9740\n",
            "Epoch 764/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0402 - binary_accuracy: 0.9740\n",
            "Epoch 765/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0402 - binary_accuracy: 0.9740\n",
            "Epoch 766/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0401 - binary_accuracy: 0.9740\n",
            "Epoch 767/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0401 - binary_accuracy: 0.9740\n",
            "Epoch 768/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0401 - binary_accuracy: 0.9740\n",
            "Epoch 769/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0400 - binary_accuracy: 0.9740\n",
            "Epoch 770/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0400 - binary_accuracy: 0.9740\n",
            "Epoch 771/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0400 - binary_accuracy: 0.9740\n",
            "Epoch 772/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0399 - binary_accuracy: 0.9740\n",
            "Epoch 773/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0399 - binary_accuracy: 0.9740\n",
            "Epoch 774/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0399 - binary_accuracy: 0.9740\n",
            "Epoch 775/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0398 - binary_accuracy: 0.9740\n",
            "Epoch 776/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0398 - binary_accuracy: 0.9740\n",
            "Epoch 777/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0398 - binary_accuracy: 0.9740\n",
            "Epoch 778/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0397 - binary_accuracy: 0.9740\n",
            "Epoch 779/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0397 - binary_accuracy: 0.9740\n",
            "Epoch 780/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0397 - binary_accuracy: 0.9740\n",
            "Epoch 781/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0397 - binary_accuracy: 0.9740\n",
            "Epoch 782/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0396 - binary_accuracy: 0.9740\n",
            "Epoch 783/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0396 - binary_accuracy: 0.9740\n",
            "Epoch 784/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0396 - binary_accuracy: 0.9740\n",
            "Epoch 785/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0395 - binary_accuracy: 0.9740\n",
            "Epoch 786/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0395 - binary_accuracy: 0.9740\n",
            "Epoch 787/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0395 - binary_accuracy: 0.9740\n",
            "Epoch 788/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0395 - binary_accuracy: 0.9740\n",
            "Epoch 789/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0394 - binary_accuracy: 0.9740\n",
            "Epoch 790/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0394 - binary_accuracy: 0.9740\n",
            "Epoch 791/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0394 - binary_accuracy: 0.9740\n",
            "Epoch 792/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0394 - binary_accuracy: 0.9740\n",
            "Epoch 793/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0393 - binary_accuracy: 0.9740\n",
            "Epoch 794/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0393 - binary_accuracy: 0.9740\n",
            "Epoch 795/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0393 - binary_accuracy: 0.9740\n",
            "Epoch 796/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0393 - binary_accuracy: 0.9740\n",
            "Epoch 797/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0392 - binary_accuracy: 0.9740\n",
            "Epoch 798/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0392 - binary_accuracy: 0.9740\n",
            "Epoch 799/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0392 - binary_accuracy: 0.9740\n",
            "Epoch 800/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0392 - binary_accuracy: 0.9740\n",
            "Epoch 801/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0391 - binary_accuracy: 0.9740\n",
            "Epoch 802/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0391 - binary_accuracy: 0.9740\n",
            "Epoch 803/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0391 - binary_accuracy: 0.9740\n",
            "Epoch 804/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0391 - binary_accuracy: 0.9740\n",
            "Epoch 805/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0391 - binary_accuracy: 0.9740\n",
            "Epoch 806/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0390 - binary_accuracy: 0.9740\n",
            "Epoch 807/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0390 - binary_accuracy: 0.9740\n",
            "Epoch 808/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0390 - binary_accuracy: 0.9740\n",
            "Epoch 809/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0390 - binary_accuracy: 0.9740\n",
            "Epoch 810/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0389 - binary_accuracy: 0.9740\n",
            "Epoch 811/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0389 - binary_accuracy: 0.9740\n",
            "Epoch 812/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0389 - binary_accuracy: 0.9740\n",
            "Epoch 813/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0389 - binary_accuracy: 0.9740\n",
            "Epoch 814/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0389 - binary_accuracy: 0.9740\n",
            "Epoch 815/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0388 - binary_accuracy: 0.9740\n",
            "Epoch 816/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0388 - binary_accuracy: 0.9740\n",
            "Epoch 817/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0388 - binary_accuracy: 0.9740\n",
            "Epoch 818/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0388 - binary_accuracy: 0.9740\n",
            "Epoch 819/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0388 - binary_accuracy: 0.9740\n",
            "Epoch 820/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0387 - binary_accuracy: 0.9740\n",
            "Epoch 821/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0387 - binary_accuracy: 0.9740\n",
            "Epoch 822/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0387 - binary_accuracy: 0.9740\n",
            "Epoch 823/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0387 - binary_accuracy: 0.9740\n",
            "Epoch 824/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0387 - binary_accuracy: 0.9740\n",
            "Epoch 825/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 826/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 827/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 828/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 829/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 830/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0385 - binary_accuracy: 0.9740\n",
            "Epoch 831/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0385 - binary_accuracy: 0.9740\n",
            "Epoch 832/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0385 - binary_accuracy: 0.9740\n",
            "Epoch 833/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0385 - binary_accuracy: 0.9740\n",
            "Epoch 834/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0385 - binary_accuracy: 0.9740\n",
            "Epoch 835/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0385 - binary_accuracy: 0.9740\n",
            "Epoch 836/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0384 - binary_accuracy: 0.9740\n",
            "Epoch 837/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0384 - binary_accuracy: 0.9740\n",
            "Epoch 838/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0384 - binary_accuracy: 0.9740\n",
            "Epoch 839/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0384 - binary_accuracy: 0.9740\n",
            "Epoch 840/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0384 - binary_accuracy: 0.9740\n",
            "Epoch 841/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0384 - binary_accuracy: 0.9740\n",
            "Epoch 842/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0383 - binary_accuracy: 0.9740\n",
            "Epoch 843/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0383 - binary_accuracy: 0.9740\n",
            "Epoch 844/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0383 - binary_accuracy: 0.9740\n",
            "Epoch 845/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0383 - binary_accuracy: 0.9740\n",
            "Epoch 846/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0383 - binary_accuracy: 0.9740\n",
            "Epoch 847/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0383 - binary_accuracy: 0.9740\n",
            "Epoch 848/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0382 - binary_accuracy: 0.9740\n",
            "Epoch 849/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0382 - binary_accuracy: 0.9740\n",
            "Epoch 850/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0382 - binary_accuracy: 0.9740\n",
            "Epoch 851/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0382 - binary_accuracy: 0.9740\n",
            "Epoch 852/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0382 - binary_accuracy: 0.9740\n",
            "Epoch 853/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0382 - binary_accuracy: 0.9740\n",
            "Epoch 854/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 855/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 856/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 857/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 858/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 859/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 860/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0381 - binary_accuracy: 0.9740\n",
            "Epoch 861/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 862/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 863/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 864/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 865/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 866/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 867/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0380 - binary_accuracy: 0.9740\n",
            "Epoch 868/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 869/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 870/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 871/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 872/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 873/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 874/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0379 - binary_accuracy: 0.9740\n",
            "Epoch 875/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 876/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 877/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 878/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 879/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 880/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 881/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 882/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9740\n",
            "Epoch 883/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 884/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 885/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 886/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 887/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 888/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 889/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 890/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0377 - binary_accuracy: 0.9740\n",
            "Epoch 891/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 892/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 893/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 894/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 895/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 896/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 897/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 898/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 899/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0376 - binary_accuracy: 0.9740\n",
            "Epoch 900/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 901/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 902/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 903/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 904/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 905/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 906/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 907/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 908/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0375 - binary_accuracy: 0.9740\n",
            "Epoch 909/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 910/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 911/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 912/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 913/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 914/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 915/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 916/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 917/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0374 - binary_accuracy: 0.9740\n",
            "Epoch 918/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 919/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 920/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 921/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 922/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 923/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 924/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 925/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 926/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 927/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0373 - binary_accuracy: 0.9740\n",
            "Epoch 928/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 929/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 930/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 931/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 932/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 933/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 934/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 935/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 936/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 937/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0372 - binary_accuracy: 0.9740\n",
            "Epoch 938/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 939/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 940/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 941/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 942/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 943/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 944/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 945/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 946/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 947/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 948/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 949/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0371 - binary_accuracy: 0.9740\n",
            "Epoch 950/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 951/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 952/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 953/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 954/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 955/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 956/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 957/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 958/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 959/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 960/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9740\n",
            "Epoch 961/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9740\n",
            "Epoch 962/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0369 - binary_accuracy: 0.9740\n",
            "Epoch 963/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9743\n",
            "Epoch 964/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9745\n",
            "Epoch 965/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9745\n",
            "Epoch 966/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9751\n",
            "Epoch 967/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9778\n",
            "Epoch 968/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9799\n",
            "Epoch 969/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 970/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 971/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 972/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 973/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 974/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 975/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 976/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 977/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 978/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 979/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 980/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 981/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 982/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 983/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 984/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 985/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 986/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0368 - binary_accuracy: 0.9800\n",
            "Epoch 987/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 988/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 989/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 990/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 991/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 992/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 993/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 994/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 995/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 996/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 997/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 998/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 999/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "Epoch 1000/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0367 - binary_accuracy: 0.9800\n",
            "56324/56324 [==============================] - 96s 2ms/step - loss: 0.0302 - binary_accuracy: 0.9800\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.4766 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.3557 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.2902 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.2334 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1888 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1619 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1471 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1388 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1337 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1304 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1281 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1265 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1253 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1244 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1237 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1232 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1228 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1224 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1221 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1219 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1217 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1216 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1214 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1213 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1212 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1211 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1211 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1210 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1209 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1208 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 198/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 199/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 200/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 201/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 202/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 203/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 204/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 205/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 206/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 207/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 208/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 209/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 210/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 211/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 212/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 213/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 214/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 215/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 216/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 217/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 218/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 219/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 220/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 221/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 222/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 223/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 224/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 225/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 226/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 227/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 228/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 229/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 230/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 231/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 232/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 233/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 234/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 235/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 236/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 237/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 238/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 239/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 240/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 241/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 242/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 243/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 244/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 245/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 246/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 247/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 248/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 249/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 250/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 251/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 252/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 253/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 254/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 255/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 256/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 257/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 258/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 259/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 260/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 261/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 262/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 263/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 264/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 265/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 266/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 267/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 268/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 269/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 270/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 271/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 272/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 273/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 274/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 275/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 276/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 277/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 278/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 279/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 280/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 281/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 282/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 283/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 284/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 285/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 286/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 287/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 288/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 289/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 290/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 291/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 292/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 293/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 294/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 295/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 296/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 297/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 298/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 299/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 300/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 301/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 302/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 303/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 304/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 305/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 306/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 307/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 308/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 309/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 310/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 311/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 312/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 313/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 314/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 315/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 316/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 317/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 318/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 319/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 320/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 321/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 322/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 323/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 324/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 325/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 326/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 327/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 328/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 329/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 330/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 331/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 332/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 333/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 334/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 335/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 336/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 337/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 338/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 339/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 340/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 341/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 342/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 343/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 344/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 345/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 346/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 347/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 348/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 349/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 350/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 351/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 352/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 353/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 354/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 355/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 356/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 357/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 358/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 359/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 360/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 361/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 362/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 363/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 364/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 365/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 366/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 367/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 368/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 369/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 370/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 371/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 372/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 373/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 374/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 375/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 376/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 377/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 378/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 379/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 380/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 381/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 382/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 383/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 384/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 385/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 386/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 387/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 388/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 389/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 390/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 391/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 392/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 393/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 394/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 395/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 396/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 397/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 398/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 399/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 400/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 401/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 402/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 403/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 404/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 405/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 406/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 407/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 408/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 409/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 410/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 411/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 412/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 413/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 414/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 415/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 416/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 417/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 418/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 419/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 420/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 421/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 422/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 423/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 424/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 425/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 426/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 427/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 428/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 429/1000\n",
            "996/996 [==============================] - 17s 18ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 430/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 431/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 432/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 433/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 434/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 435/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 436/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 437/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 438/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 439/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 440/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 441/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 442/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 443/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 444/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 445/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 446/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 447/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 448/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 449/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 450/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 451/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 452/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 453/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 454/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 455/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 456/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 457/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 458/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 459/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 460/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 461/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 462/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 463/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 464/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 465/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 466/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 467/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 468/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 469/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 470/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 471/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 472/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 473/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 474/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 475/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 476/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 477/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 478/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 479/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 480/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 481/1000\n",
            "996/996 [==============================] - 17s 18ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 482/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 483/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 484/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 485/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 486/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 487/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 488/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 489/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 490/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 491/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 492/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 493/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 494/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 495/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 496/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 497/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 498/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 499/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 500/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 501/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 502/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 503/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 504/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 505/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 506/1000\n",
            "996/996 [==============================] - 17s 18ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 507/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 508/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 509/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 510/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 511/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 512/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 513/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 514/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 515/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 516/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 517/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 518/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 519/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 520/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 521/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 522/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 523/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 524/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 525/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 526/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 527/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 528/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 529/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 530/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 531/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 532/1000\n",
            "996/996 [==============================] - 17s 18ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 533/1000\n",
            "317/996 [========>.....................] - ETA: 11s - loss: 0.1212 - binary_accuracy: 0.9738"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resultados de redes neuronales 1 y 2 salidas"
      ],
      "metadata": {
        "id": "7fjQ33aLQOcr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV1bJkgEnqDB",
        "outputId": "9fdfb3fe-073a-4351-ba69-9a19c44def21"
      },
      "source": [
        "# Datasets\n",
        "df = pd.read_csv(path + 'Dataset_de_prueba_oficial_1.csv', sep=';')\n",
        "df2 = pd.read_csv(path + 'Dataset_de_prueba_oficial_2.csv', sep=';')\n",
        "\n",
        "# Definiciones Arquitecturas\n",
        "#activation= 'sigmoid', 'relu', 'softmax', 'tanh'\n",
        "#loss= 'categorical_crossentropy', \n",
        "#Optimizador = 'adams', 'sgd', 'Adagrad', 'Adamax'\n",
        "\n",
        "#Modificar arreglo\n",
        "ejecuciones = [\n",
        "               #['Red9','sgd','categorical_crossentropy',[[30,'relu'],[65,'tanh'],[100, 'sigmoid'], [65,'relu'], [30,'tanh'], [10, 'sigmoid']]]\n",
        "               #['Red10','adam','categorical_crossentropy',[[25,'relu'],[60,'tanh'],[90, 'sigmoid'], [60,'relu'], [30,'tanh'], [15, 'sigmoid']]],\n",
        "               #['Red11','Adagrad','categorical_crossentropy',[[30,'sigmoid'],[55,'relu'],[90, 'tanh'], [65,'relu'], [35,'relu'], [10, 'sigmoid']]],\n",
        "               #['Red12','sgd','categorical_crossentropy',[[25,'sigmoid'],[50,'relu'],[90, 'tanh'], [120,'relu'], [80,'relu'], [50, 'sigmoid'], [20, 'sigmoid']]],\n",
        "               #['Red13','Adamax','categorical_crossentropy',[[20,'relu'],[50, 'sigmoid'],[25,'relu']]],\n",
        "               #['Red14','Adamax','categorical_crossentropy',[[25,'elu'],[40, 'sigmoid'],[60,'tanh'], [35,'sigmoid'], [15,'relu']]],\n",
        "               ['Red15','Adagrad','categorical_crossentropy',[[25,'sigmoid'],[50, 'elu'],[70,'relu'],[100,'tanh'], [65,'relu'], [25, 'sigmoid'], [10, 'elu']]]\n",
        "               #['Red16','adam','categorical_crossentropy',[[30,'sigmoid'],[55, 'elu'],[75,'relu'],[100,'tanh'], [70,'relu'], [35, 'sigmoid'], [15, 'elu']]],\n",
        "               #['Red17','sgd','categorical_crossentropy',[[25,'sigmoid'],[50, 'relu'],[75,'elu'],[100,'sigmoid'], [70,'tanh'], [35, 'relu'], [15, 'elu']]],\n",
        "               #['Red18','adam','categorical_crossentropy',[[20,'elu'],[50, 'relu'],[25,'elu'],[10,'sigmoid']]],\n",
        "               #['Red19','adam','categorical_crossentropy',[[25,'relu'],[45, 'softmax'],[20,'sigmoid'],[5,'sigmoid']]],\n",
        "               #['Red20','sgd','categorical_crossentropy',[[20,'softmax'],[50, 'sigmoid'],[25,'tanh'],[10,'relu']]]\n",
        "               ]\n",
        "arr1 = []\n",
        "arr2 = []\n",
        "for nombre, optimizador, f_perdida, arquitectura in ejecuciones:\n",
        "  redes = pd.read_excel(path + 'Diseño_arquitecturas.xlsx')\n",
        "  array_capas=[]\n",
        "  contador = 1\n",
        "  for capa in arquitectura:\n",
        "    array_capas.append([nombre, contador, capa[0], capa[1], optimizador])\n",
        "    contador+=1\n",
        "  nueva_Arquitectura = pd.DataFrame(array_capas,columns = ['Red', 'Capa_oculta', 'Neuronas', 'Funcion_activacion', 'Optimizador'])\n",
        "  redes = pd.concat([redes, nueva_Arquitectura])\n",
        "  redes.to_excel(path + 'Diseño_arquitecturas.xlsx',index = False)\n",
        "  for salida in range (0, 2):\n",
        "    for dataset in range (0, 2):\n",
        "      for i in range (1, 6):\n",
        "        # Entrenar la red\n",
        "        if(dataset == 0):\n",
        "          if(salida==0):\n",
        "            precision, perdida, Modelo =  red_neuronal_una_salida(df, optimizador, f_perdida, arquitectura, 1000, 2200)\n",
        "            arr1.append([nombre, \"Dataset1\", i, optimizador, f_perdida, precision, perdida])\n",
        "          else:\n",
        "            precision, perdida, Modelo =  red_neuronal_dos_salidas(df, optimizador, f_perdida, arquitectura, 1000, 2200)\n",
        "            arr2.append([nombre, \"Dataset1\", i, optimizador, f_perdida, precision, perdida])\n",
        "        else:\n",
        "          if(salida==0):\n",
        "            precision, perdida, Modelo = red_neuronal_una_salida(df2, optimizador, f_perdida, arquitectura, 1000, 1550)\n",
        "            arr1.append([nombre, \"Dataset2\", i, optimizador, f_perdida, precision, perdida])\n",
        "          else:\n",
        "            precision, perdida, Modelo =  red_neuronal_dos_salidas(df, optimizador, f_perdida, arquitectura, 1000, 1550)\n",
        "            arr2.append([nombre, \"Dataset2\", i, optimizador, f_perdida, precision, perdida])\n",
        "      # Guardar el Modelo\n",
        "      if(dataset == 0):\n",
        "        if(salida == 0):\n",
        "          Modelo.save(path + 'Modelos/'+ nombre + '_D1S1.h5')\n",
        "        else:\n",
        "          Modelo.save(path + 'Modelos/'+ nombre + '_D1S2.h5')\n",
        "      else:\n",
        "        if(salida == 0):\n",
        "          Modelo.save(path + 'Modelos/'+ nombre + '_D2S1.h5')\n",
        "        else:\n",
        "          Modelo.save(path + 'Modelos/'+ nombre + '_D2S2.h5')\n",
        "\n",
        "# Documentar red\n",
        "df_glob1 = pd.read_excel(path + 'Datos_Red_1_salidas.xlsx')\n",
        "df_salida1 = pd.DataFrame(arr1, columns = ['Red', 'Dataset', 'Iteracion', 'Optimizador', 'F_Perdida', 'Precision', 'Perdida (loss)'])\n",
        "df_glob1 = pd.concat([df_glob1, df_salida1])\n",
        "df_glob1.to_excel(path + 'Datos_Red_1_salidas.xlsx',index = False)\n",
        "\n",
        "df_glob2 = pd.read_excel(path + 'Datos_Red_2_salidas.xlsx')\n",
        "df_salida2 = pd.DataFrame(arr2, columns = ['Red', 'Dataset', 'Iteracion', 'Optimizador', 'F_Perdida', 'Precision', 'Perdida (loss)'])\n",
        "df_glob2 = pd.concat([df_glob2, df_salida2])\n",
        "df_glob2.to_excel(path + 'Datos_Red_2_salidas.xlsx', index = False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Modelo ya generado\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Ya se generó.\n",
            "Modelo ya generado\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1536 - binary_accuracy: 0.9730\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1207 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 17s 18ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1193 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1191 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1189 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1186 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1182 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1177 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1170 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1160 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1147 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1126 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1092 - binary_accuracy: 0.9740\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1035 - binary_accuracy: 0.9740\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0940 - binary_accuracy: 0.9740\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0801 - binary_accuracy: 0.9740\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0664 - binary_accuracy: 0.9740\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0567 - binary_accuracy: 0.9740\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0503 - binary_accuracy: 0.9740\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0458 - binary_accuracy: 0.9740\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0426 - binary_accuracy: 0.9740\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0402 - binary_accuracy: 0.9740\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0376 - binary_accuracy: 0.9750\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0369 - binary_accuracy: 0.9793\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0364 - binary_accuracy: 0.9799\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0360 - binary_accuracy: 0.9800\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0357 - binary_accuracy: 0.9800\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0355 - binary_accuracy: 0.9800\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0353 - binary_accuracy: 0.9800\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0352 - binary_accuracy: 0.9800\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0351 - binary_accuracy: 0.9801\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0349 - binary_accuracy: 0.9801\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0348 - binary_accuracy: 0.9801\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0347 - binary_accuracy: 0.9802\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0347 - binary_accuracy: 0.9802\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0346 - binary_accuracy: 0.9803\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0345 - binary_accuracy: 0.9803\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0345 - binary_accuracy: 0.9803\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0344 - binary_accuracy: 0.9804\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0344 - binary_accuracy: 0.9804\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0343 - binary_accuracy: 0.9804\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0343 - binary_accuracy: 0.9804\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9805\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 18s 18ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 198/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 199/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 200/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 201/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 202/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 203/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 204/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 205/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 206/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 00206: early stopping\n",
            "56324/56324 [==============================] - 90s 2ms/step - loss: 0.0276 - binary_accuracy: 0.9840\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 15s 14ms/step - loss: 0.1485 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1195 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1189 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1186 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1183 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1178 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1171 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1162 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1150 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1132 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1105 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.1060 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0982 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0855 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0705 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0589 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0512 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0460 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0425 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0402 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0386 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0376 - binary_accuracy: 0.9754\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0364 - binary_accuracy: 0.9800\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0360 - binary_accuracy: 0.9800\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0357 - binary_accuracy: 0.9800\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0354 - binary_accuracy: 0.9800\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0352 - binary_accuracy: 0.9800\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0351 - binary_accuracy: 0.9801\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0349 - binary_accuracy: 0.9801\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0348 - binary_accuracy: 0.9801\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0347 - binary_accuracy: 0.9802\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0346 - binary_accuracy: 0.9802\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0346 - binary_accuracy: 0.9802\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0345 - binary_accuracy: 0.9802\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0344 - binary_accuracy: 0.9803\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0344 - binary_accuracy: 0.9803\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0343 - binary_accuracy: 0.9803\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0343 - binary_accuracy: 0.9804\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0343 - binary_accuracy: 0.9804\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 14s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 14s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 198/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 199/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 200/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 201/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 202/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 203/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 204/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 205/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 206/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 207/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 208/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 209/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 210/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 211/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 212/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 213/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 214/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 215/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 216/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 217/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 218/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 219/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 220/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 00220: early stopping\n",
            "56324/56324 [==============================] - 96s 2ms/step - loss: 0.0282 - binary_accuracy: 0.9812\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 16s 15ms/step - loss: 0.1447 - binary_accuracy: 0.9730\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1189 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1185 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1180 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1173 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1162 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1146 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1118 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1068 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0976 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0824 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0659 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0545 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0477 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0435 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0407 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0389 - binary_accuracy: 0.9746\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0378 - binary_accuracy: 0.9792\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0370 - binary_accuracy: 0.9800\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0365 - binary_accuracy: 0.9799\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0361 - binary_accuracy: 0.9798\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0358 - binary_accuracy: 0.9796\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0356 - binary_accuracy: 0.9794\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0354 - binary_accuracy: 0.9793\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0353 - binary_accuracy: 0.9793\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0352 - binary_accuracy: 0.9793\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0351 - binary_accuracy: 0.9793\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0350 - binary_accuracy: 0.9793\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0349 - binary_accuracy: 0.9793\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0348 - binary_accuracy: 0.9793\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0348 - binary_accuracy: 0.9794\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0347 - binary_accuracy: 0.9794\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0347 - binary_accuracy: 0.9794\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0346 - binary_accuracy: 0.9795\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0346 - binary_accuracy: 0.9795\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0345 - binary_accuracy: 0.9796\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0345 - binary_accuracy: 0.9796\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0345 - binary_accuracy: 0.9797\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0344 - binary_accuracy: 0.9797\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0344 - binary_accuracy: 0.9797\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0344 - binary_accuracy: 0.9797\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0343 - binary_accuracy: 0.9798\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0343 - binary_accuracy: 0.9798\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0343 - binary_accuracy: 0.9798\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9799\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9799\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9799\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9800\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9800\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0341 - binary_accuracy: 0.9800\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0341 - binary_accuracy: 0.9801\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0341 - binary_accuracy: 0.9801\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0341 - binary_accuracy: 0.9801\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0341 - binary_accuracy: 0.9801\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 00197: early stopping\n",
            "56324/56324 [==============================] - 103s 2ms/step - loss: 0.0271 - binary_accuracy: 0.9851\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1468 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1190 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1186 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1182 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1176 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1168 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1156 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1137 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.1107 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.1055 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0964 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0824 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0674 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0566 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0497 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0450 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0418 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0396 - binary_accuracy: 0.9740\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0382 - binary_accuracy: 0.9747\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0372 - binary_accuracy: 0.9796\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0366 - binary_accuracy: 0.9800\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0361 - binary_accuracy: 0.9800\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0358 - binary_accuracy: 0.9800\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0355 - binary_accuracy: 0.9800\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0353 - binary_accuracy: 0.9800\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0352 - binary_accuracy: 0.9799\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0350 - binary_accuracy: 0.9799\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0349 - binary_accuracy: 0.9800\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0348 - binary_accuracy: 0.9800\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0347 - binary_accuracy: 0.9799\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0347 - binary_accuracy: 0.9799\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0346 - binary_accuracy: 0.9799\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0345 - binary_accuracy: 0.9800\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0345 - binary_accuracy: 0.9799\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0344 - binary_accuracy: 0.9799\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0344 - binary_accuracy: 0.9799\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0344 - binary_accuracy: 0.9799\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0343 - binary_accuracy: 0.9799\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0343 - binary_accuracy: 0.9799\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0343 - binary_accuracy: 0.9799\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0342 - binary_accuracy: 0.9800\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0342 - binary_accuracy: 0.9800\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0342 - binary_accuracy: 0.9799\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0342 - binary_accuracy: 0.9800\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0341 - binary_accuracy: 0.9800\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0341 - binary_accuracy: 0.9800\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0341 - binary_accuracy: 0.9800\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0341 - binary_accuracy: 0.9800\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0341 - binary_accuracy: 0.9800\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9800\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9800\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9801\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9801\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9801\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9801\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9801\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9801\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9801\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 15s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 15s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9802\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9803\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 198/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 199/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 200/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 201/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 202/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 203/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 204/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 205/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 206/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 207/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 208/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 209/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 210/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 211/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 212/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 213/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 214/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 215/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 216/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 217/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 218/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 219/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 220/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 221/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 222/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 223/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 224/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 225/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 226/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 227/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 228/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 229/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 230/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 231/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 232/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 233/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 234/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 235/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 236/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 00236: early stopping\n",
            "56324/56324 [==============================] - 104s 2ms/step - loss: 0.0272 - binary_accuracy: 0.9848\n",
            "Epoch 1/1000\n",
            "996/996 [==============================] - 17s 16ms/step - loss: 0.1467 - binary_accuracy: 0.9740\n",
            "Epoch 2/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1195 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1193 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1191 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1188 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1184 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1179 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1173 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1163 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1149 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.1126 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1087 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.1017 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0898 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0745 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0615 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0530 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0475 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0436 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0409 - binary_accuracy: 0.9740\n",
            "Epoch 65/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0390 - binary_accuracy: 0.9740\n",
            "Epoch 66/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0378 - binary_accuracy: 0.9748\n",
            "Epoch 67/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0370 - binary_accuracy: 0.9795\n",
            "Epoch 68/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0365 - binary_accuracy: 0.9800\n",
            "Epoch 69/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0361 - binary_accuracy: 0.9800\n",
            "Epoch 70/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0358 - binary_accuracy: 0.9800\n",
            "Epoch 71/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0355 - binary_accuracy: 0.9800\n",
            "Epoch 72/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0353 - binary_accuracy: 0.9800\n",
            "Epoch 73/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0352 - binary_accuracy: 0.9800\n",
            "Epoch 74/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0350 - binary_accuracy: 0.9800\n",
            "Epoch 75/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0349 - binary_accuracy: 0.9799\n",
            "Epoch 76/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0348 - binary_accuracy: 0.9800\n",
            "Epoch 77/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0347 - binary_accuracy: 0.9800\n",
            "Epoch 78/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0347 - binary_accuracy: 0.9801\n",
            "Epoch 79/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0346 - binary_accuracy: 0.9801\n",
            "Epoch 80/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0345 - binary_accuracy: 0.9801\n",
            "Epoch 81/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0345 - binary_accuracy: 0.9801\n",
            "Epoch 82/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0344 - binary_accuracy: 0.9801\n",
            "Epoch 83/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0344 - binary_accuracy: 0.9802\n",
            "Epoch 84/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0343 - binary_accuracy: 0.9801\n",
            "Epoch 85/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0343 - binary_accuracy: 0.9802\n",
            "Epoch 86/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0343 - binary_accuracy: 0.9802\n",
            "Epoch 87/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0342 - binary_accuracy: 0.9802\n",
            "Epoch 88/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0342 - binary_accuracy: 0.9802\n",
            "Epoch 89/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0342 - binary_accuracy: 0.9802\n",
            "Epoch 90/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0342 - binary_accuracy: 0.9802\n",
            "Epoch 91/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0341 - binary_accuracy: 0.9802\n",
            "Epoch 92/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0341 - binary_accuracy: 0.9802\n",
            "Epoch 93/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0341 - binary_accuracy: 0.9802\n",
            "Epoch 94/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0341 - binary_accuracy: 0.9802\n",
            "Epoch 95/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 96/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 97/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 98/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 99/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 100/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0340 - binary_accuracy: 0.9803\n",
            "Epoch 101/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0340 - binary_accuracy: 0.9802\n",
            "Epoch 102/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9802\n",
            "Epoch 103/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 104/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 105/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 106/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 107/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 108/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 109/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 110/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 111/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 112/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0339 - binary_accuracy: 0.9803\n",
            "Epoch 113/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 114/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 115/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 116/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 117/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 118/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 119/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 120/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 121/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 122/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9803\n",
            "Epoch 123/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 124/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 125/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 126/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 127/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 128/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 129/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 130/1000\n",
            "996/996 [==============================] - 16s 16ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 131/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 132/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 133/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 134/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 135/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 136/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 137/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 138/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 139/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 140/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 141/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 142/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 143/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 144/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 145/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 146/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 147/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 148/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 149/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 150/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 151/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 152/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 153/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 154/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 155/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 156/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 157/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 158/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 159/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 160/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 161/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 162/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 163/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 164/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 165/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 166/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 167/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 168/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 169/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 170/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 171/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 172/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 173/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 174/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 175/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 176/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 177/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 178/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 179/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 180/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 181/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 182/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 183/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 184/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 185/1000\n",
            "996/996 [==============================] - 16s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 186/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 187/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 188/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 189/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 190/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 191/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 192/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 193/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 194/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 195/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 196/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 197/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 198/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 199/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 200/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 201/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 202/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 203/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 204/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 205/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 206/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 207/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 208/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 209/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 210/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 211/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 212/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 213/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 214/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 215/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 216/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 217/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 218/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 219/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 220/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 221/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 222/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 223/1000\n",
            "996/996 [==============================] - 17s 17ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 00223: early stopping\n",
            "56324/56324 [==============================] - 105s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9833\n",
            "Epoch 1/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1398 - binary_accuracy: 0.9733\n",
            "Epoch 2/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1198 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1195 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1189 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1184 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1178 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1168 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1152 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1123 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.1066 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0940 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0741 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0582 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0488 - binary_accuracy: 0.9740\n",
            "Epoch 63/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0430 - binary_accuracy: 0.9740\n",
            "Epoch 64/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0396 - binary_accuracy: 0.9741\n",
            "Epoch 65/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0377 - binary_accuracy: 0.9790\n",
            "Epoch 66/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0366 - binary_accuracy: 0.9800\n",
            "Epoch 67/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0360 - binary_accuracy: 0.9800\n",
            "Epoch 68/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0355 - binary_accuracy: 0.9801\n",
            "Epoch 69/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0352 - binary_accuracy: 0.9802\n",
            "Epoch 70/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0350 - binary_accuracy: 0.9802\n",
            "Epoch 71/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0348 - binary_accuracy: 0.9802\n",
            "Epoch 72/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0347 - binary_accuracy: 0.9803\n",
            "Epoch 73/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0345 - binary_accuracy: 0.9803\n",
            "Epoch 74/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0344 - binary_accuracy: 0.9803\n",
            "Epoch 75/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0344 - binary_accuracy: 0.9803\n",
            "Epoch 76/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0343 - binary_accuracy: 0.9803\n",
            "Epoch 77/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 78/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0342 - binary_accuracy: 0.9804\n",
            "Epoch 79/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0341 - binary_accuracy: 0.9803\n",
            "Epoch 80/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 81/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0341 - binary_accuracy: 0.9804\n",
            "Epoch 82/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 83/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 84/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 85/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 86/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 87/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 88/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 89/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 90/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 91/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9805\n",
            "Epoch 92/1000\n",
            "1413/1413 [==============================] - 18s 13ms/step - loss: 0.0339 - binary_accuracy: 0.9805\n",
            "Epoch 93/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 94/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 95/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9804\n",
            "Epoch 96/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 97/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 98/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 99/1000\n",
            "1413/1413 [==============================] - 22s 15ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 100/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 101/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 102/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 103/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 104/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0338 - binary_accuracy: 0.9805\n",
            "Epoch 105/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 106/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 107/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 108/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 109/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 110/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 111/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 112/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 113/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 114/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 115/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 116/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 117/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 118/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 119/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 120/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 121/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 122/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 123/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 124/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 125/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 126/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 127/1000\n",
            "1413/1413 [==============================] - 19s 13ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 128/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 129/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 130/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 131/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 132/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 133/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 134/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 135/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 136/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 137/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 138/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 139/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 140/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 141/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 142/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 143/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 144/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 145/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 146/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9804\n",
            "Epoch 147/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 148/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 149/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 150/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 151/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 152/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0337 - binary_accuracy: 0.9805\n",
            "Epoch 153/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 154/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 155/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 156/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 157/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 158/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 159/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 160/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 161/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 162/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 163/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 164/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 165/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 166/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 167/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 168/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 169/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 170/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 171/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 172/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 173/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 174/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 175/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 176/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 177/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 178/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 179/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 180/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 181/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 182/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 183/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 184/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 185/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 186/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 187/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 188/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 189/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 190/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 191/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 192/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 193/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 194/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 195/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 196/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 197/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 198/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 199/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 200/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 201/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 202/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 203/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 204/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 205/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 206/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 207/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 208/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 209/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 210/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 211/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 212/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 213/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 214/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 215/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 216/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 217/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 218/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 219/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 220/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 221/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 222/1000\n",
            "1413/1413 [==============================] - 19s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 223/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 224/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9804\n",
            "Epoch 225/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 226/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 227/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 228/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0336 - binary_accuracy: 0.9805\n",
            "Epoch 00228: early stopping\n",
            "56324/56324 [==============================] - 112s 2ms/step - loss: 0.0277 - binary_accuracy: 0.9832\n",
            "Epoch 1/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1404 - binary_accuracy: 0.9733\n",
            "Epoch 2/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 3/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 4/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 5/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 6/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 7/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 8/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 9/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 10/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 11/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 12/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 13/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 14/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 15/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1206 - binary_accuracy: 0.9740\n",
            "Epoch 16/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 17/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 18/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 19/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 20/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 21/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 22/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 23/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 24/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 25/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 26/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 27/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 28/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1205 - binary_accuracy: 0.9740\n",
            "Epoch 29/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 30/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 31/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 32/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 33/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 34/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 35/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1204 - binary_accuracy: 0.9740\n",
            "Epoch 36/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 37/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 38/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1203 - binary_accuracy: 0.9740\n",
            "Epoch 39/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 40/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 41/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1202 - binary_accuracy: 0.9740\n",
            "Epoch 42/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1201 - binary_accuracy: 0.9740\n",
            "Epoch 43/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 44/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1200 - binary_accuracy: 0.9740\n",
            "Epoch 45/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.1199 - binary_accuracy: 0.9740\n",
            "Epoch 46/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1197 - binary_accuracy: 0.9740\n",
            "Epoch 47/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1196 - binary_accuracy: 0.9740\n",
            "Epoch 48/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1194 - binary_accuracy: 0.9740\n",
            "Epoch 49/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1192 - binary_accuracy: 0.9740\n",
            "Epoch 50/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1188 - binary_accuracy: 0.9740\n",
            "Epoch 51/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1183 - binary_accuracy: 0.9740\n",
            "Epoch 52/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1176 - binary_accuracy: 0.9740\n",
            "Epoch 53/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1166 - binary_accuracy: 0.9740\n",
            "Epoch 54/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1149 - binary_accuracy: 0.9740\n",
            "Epoch 55/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1118 - binary_accuracy: 0.9740\n",
            "Epoch 56/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.1056 - binary_accuracy: 0.9740\n",
            "Epoch 57/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0922 - binary_accuracy: 0.9740\n",
            "Epoch 58/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0712 - binary_accuracy: 0.9740\n",
            "Epoch 59/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0550 - binary_accuracy: 0.9740\n",
            "Epoch 60/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0461 - binary_accuracy: 0.9740\n",
            "Epoch 61/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0411 - binary_accuracy: 0.9740\n",
            "Epoch 62/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0384 - binary_accuracy: 0.9752\n",
            "Epoch 63/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0369 - binary_accuracy: 0.9800\n",
            "Epoch 64/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0361 - binary_accuracy: 0.9800\n",
            "Epoch 65/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0356 - binary_accuracy: 0.9800\n",
            "Epoch 66/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.0352 - binary_accuracy: 0.9800\n",
            "Epoch 67/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0349 - binary_accuracy: 0.9800\n",
            "Epoch 68/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.0348 - binary_accuracy: 0.9801\n",
            "Epoch 69/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0346 - binary_accuracy: 0.9801\n",
            "Epoch 70/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0345 - binary_accuracy: 0.9801\n",
            "Epoch 71/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0344 - binary_accuracy: 0.9801\n",
            "Epoch 72/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0343 - binary_accuracy: 0.9802\n",
            "Epoch 73/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0343 - binary_accuracy: 0.9802\n",
            "Epoch 74/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0342 - binary_accuracy: 0.9802\n",
            "Epoch 75/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0342 - binary_accuracy: 0.9802\n",
            "Epoch 76/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.0341 - binary_accuracy: 0.9803\n",
            "Epoch 77/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0341 - binary_accuracy: 0.9803\n",
            "Epoch 78/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9803\n",
            "Epoch 79/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9803\n",
            "Epoch 80/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.0340 - binary_accuracy: 0.9804\n",
            "Epoch 81/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0340 - binary_accuracy: 0.9803\n",
            "Epoch 82/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 83/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 84/1000\n",
            "1413/1413 [==============================] - 20s 14ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 85/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 86/1000\n",
            "1413/1413 [==============================] - 21s 15ms/step - loss: 0.0339 - binary_accuracy: 0.9804\n",
            "Epoch 87/1000\n",
            "1275/1413 [==========================>...] - ETA: 2s - loss: 0.0339 - binary_accuracy: 0.9804"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ordenar\n",
        "df_glob1 = pd.read_excel(path + 'Datos_Red_1_salidas.xlsx')\n",
        "df_glob2 = pd.read_excel(path + 'Datos_Red_2_salidas.xlsx')\n",
        "redes = pd.read_excel(path + 'Diseño_arquitecturas.xlsx')\n",
        "\n",
        "redes = redes.sort_values(['Red','Capa_oculta']).reset_index(drop = True)\n",
        "df_glob1 = df_glob1.sort_values(['Red', 'Dataset', 'Iteracion']).reset_index(drop = True)\n",
        "df_glob2 = df_glob2.sort_values(['Red', 'Dataset', 'Iteracion']).reset_index(drop = True)\n",
        "\n",
        "redes.to_excel(path + 'Diseño_arquitecturas.xlsx',index = False)\n",
        "df_glob1.to_excel(path + 'Datos_Red_1_salidas.xlsx',index = False)\n",
        "df_glob2.to_excel(path + 'Datos_Red_2_salidas.xlsx',index = False)"
      ],
      "metadata": {
        "id": "BmeSq9X5cdY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_COkKkvu7YNV"
      },
      "source": [
        "##Cargar modelo existente"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAMIvurR40KK"
      },
      "source": [
        "# Recrea exactamente el mismo modelo solo desde el archivo\n",
        "model = keras.models.load_model(path + '/Modelos/Red19_D2S2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de precisión del modelo individual"
      ],
      "metadata": {
        "id": "oa1MOnkYSksH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset 1"
      ],
      "metadata": {
        "id": "FaVpYe4EDfkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and a test set\n",
        "Train1 = df[(df['Mes_envio']<0.5)]\n",
        "X_train1 = Train1.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "y_train1 = Train1[\"RESPONDIDA\"].to_numpy()\n",
        "\n",
        "Test1 = df[(df['Mes_envio']>=0.5)]\n",
        "X_test1 = Test1.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "y_test1 = Test1[\"RESPONDIDA\"].to_numpy()\n"
      ],
      "metadata": {
        "id": "jQXS05pFSseg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar solo si es de dos salidas\n",
        "y_test1 = np_utils.to_categorical(y_test1)\n",
        "y_train1 = np_utils.to_categorical(y_train1)"
      ],
      "metadata": {
        "id": "Lt9G9z73UeBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test1, y_test1)\n",
        "precision = scores[1]\n",
        "perdida = scores[0]\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Perdida: \", perdida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWpD7_VaSzVQ",
        "outputId": "cd92f9f6-5443-44c8-c63d-c454fa658271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "56324/56324 [==============================] - 67s 1ms/step - loss: 0.1272 - binary_accuracy: 0.9721\n",
            "Precision:  0.9721478223800659\n",
            "Perdida:  0.12717977166175842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset 2"
      ],
      "metadata": {
        "id": "BKr1SwOBLQnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into a training set and a test set\n",
        "Train2 = df2[(df2['Mes_envio']<0.5)]\n",
        "X_train2 = Train2.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "y_train2 = Train2[\"RESPONDIDA\"].to_numpy()\n",
        "\n",
        "Test2 = df2[(df2['Mes_envio']>=0.5)]\n",
        "X_test2 = Test2.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "y_test2 = Test2[\"RESPONDIDA\"].to_numpy()"
      ],
      "metadata": {
        "id": "8M2OHOUHLfJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicar solo si es de dos salidas\n",
        "y_test2 = np_utils.to_categorical(y_test2)\n",
        "y_train2 = np_utils.to_categorical(y_train2)"
      ],
      "metadata": {
        "id": "_njnxAQoRa1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test2, y_test2)\n",
        "precision = scores[1]\n",
        "perdida = scores[0]\n",
        "print(\"Precision: \", precision)\n",
        "print(\"Perdida: \", perdida)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbgHZdQ5RbEP",
        "outputId": "5cc8026b-e96d-45cf-e212-5367975991c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30570/30570 [==============================] - 36s 1ms/step - loss: 0.0646 - binary_accuracy: 0.9632\n",
            "Precision:  0.9632233381271362\n",
            "Perdida:  0.06461578607559204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Validación de Modelo, Matriz de Confusión"
      ],
      "metadata": {
        "id": "AKUE0tYTjG1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recrea exactamente el mismo modelo solo desde el archivo\n",
        "mejor_modelo = keras.models.load_model(path + '/Mejores_modelos/Red36_D2S2.h5')"
      ],
      "metadata": {
        "id": "BpzOh64F4tPN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset N°1\n",
        "X = df.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "Y = df[\"RESPONDIDA\"].to_numpy()\n",
        "Y = np_utils.to_categorical(Y)"
      ],
      "metadata": {
        "id": "xEyfKTOhj1Yn"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset N°2\n",
        "X = df2.drop('RESPONDIDA', axis=1).to_numpy()\n",
        "Y = df2[\"RESPONDIDA\"].to_numpy()\n",
        "Y = np_utils.to_categorical(Y)"
      ],
      "metadata": {
        "id": "9Y8LvVhaj7pP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "new_predictions = mejor_modelo.predict(X)\n",
        "confusion = confusion_matrix(Y.argmax(axis=1), new_predictions.argmax(axis=1))\n",
        "#confusion = confusion_matrix(y_test, new_predictions)\n",
        "print('Confusion Matrix\\n')\n",
        "print(confusion)\n",
        "group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
        "                confusion.flatten()]\n",
        "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
        "                     confusion.flatten()/np.sum(confusion)]\n",
        "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
        "          zip(group_names,group_counts,group_percentages)]\n",
        "labels = np.asarray(labels).reshape(2,2)\n",
        "sns.heatmap(confusion, annot=labels, fmt='', cmap='Blues')"
      ],
      "metadata": {
        "id": "JAfKqrORjMmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "outputId": "175a1594-8207-418d-ddb4-48c241f62715"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "\n",
            "[[3856544   28000]\n",
            " [  41783   65360]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fb6888753d0>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(confusion[:,1], axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPR4yHwCBaO6",
        "outputId": "a7639457-5c16-4637-d6b4-b7157be85ba6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "123633"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    }
  ]
}